
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>differential_geometry.dense_ops &#8212; Pisces-Geometry  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/differential_geometry/dense_ops';</script>
    <link rel="icon" href="../../_static/pm_favicon.svg"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Pisces-Geometry  documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getting_started.html">
    Quick-start Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../auto_examples/index.html">
    Example Gallery
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../reference/index.html">
    PyMetric User Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar hide-on-wide">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../getting_started.html">
    Quick-start Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../auto_examples/index.html">
    Example Gallery
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../reference/index.html">
    PyMetric User Guide
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api.html">
    API
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">differential_geometry.dense_ops</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for differential_geometry.dense_ops</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Differential geometry operations on dense arrays.</span>

<span class="sd">These methods provide a differential geometry backend which is designed to interact well</span>
<span class="sd">with the &quot;dense&quot; representation of tensor fields in PyMetric; specifically, the use</span>
<span class="sd">of full arrays to represent tensor fields.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Sequence</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numpy.typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">ArrayLike</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.dense_utils</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">_dense_contract_index_with_diagonal_metric</span><span class="p">,</span>
    <span class="n">_dense_contract_index_with_metric</span><span class="p">,</span>
    <span class="n">infer_metric_type</span><span class="p">,</span>
<span class="p">)</span>


<span class="c1"># =================================== #</span>
<span class="c1"># Gradient Methods                    #</span>
<span class="c1"># =================================== #</span>
<span class="c1"># These methods are used to compute the gradient of dense</span>
<span class="c1"># tensor fields.</span>
<div class="viewcode-block" id="dense_gradient_covariant">
<a class="viewcode-back" href="../../_as_gen/differential_geometry.dense_ops.dense_gradient_covariant.html#differential_geometry.dense_ops.dense_gradient_covariant">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">dense_gradient_covariant</span><span class="p">(</span>
    <span class="n">tensor_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">ndim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
    <span class="n">field_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_indices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_order</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ArrayLike</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">_</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the element-wise covariant gradient of a tensor field.</span>

<span class="sd">    This function computes the raw partial derivatives :math:`\partial_\mu T` of a tensor (or array) field</span>
<span class="sd">    with respect to its grid coordinates, treating each tensor component independently.</span>

<span class="sd">    It returns the gradient along all spatial axes (or a subset, if specified), storing results</span>
<span class="sd">    in the final axis of the output. This is the covariant gradient in the sense of component-wise</span>
<span class="sd">    partial derivatives, without applying connection terms (i.e., no Christoffel symbols). It is **not**</span>
<span class="sd">    the covariant derivative.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        This is a low-level utility function. It does **not** validate input shapes or ensure</span>
<span class="sd">        coordinate consistency. It assumes that the tensor rank and grid structure are correct.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor_field : numpy.ndarray</span>
<span class="sd">        Tensor field of shape ``(F_1, ..., F_m, N, ...)``, where the last `rank` axes</span>
<span class="sd">        are the tensor index dimensions. The partial derivatives are computed over the first `m` axes.</span>

<span class="sd">        .. hint::</span>

<span class="sd">            Because this function is a low-level callable, it does not enforce the density of</span>
<span class="sd">            the elements in the trailing dimensions of the field. This can be used in some cases where</span>
<span class="sd">            the field is not **technically** a tensor field.</span>

<span class="sd">    rank : int</span>
<span class="sd">        Number of trailing axes that represent tensor indices (i.e., tensor rank). The `rank` determines</span>
<span class="sd">        the number of identified coordinate axes and therefore determines the shape of the returned array.</span>
<span class="sd">    ndim: int</span>
<span class="sd">        The number of total dimensions in the relevant coordinate system. This determines the maximum allowed value</span>
<span class="sd">        for ``m`` and the number of elements in the trailing dimension of the output.</span>
<span class="sd">    *varargs :</span>
<span class="sd">        Grid spacing for each spatial axis. Follows the same format as :func:`numpy.gradient`, and can be:</span>

<span class="sd">        - A single scalar (applied to all spatial axes),</span>
<span class="sd">        - A list of scalars (one per axis),</span>
<span class="sd">        - A list of coordinate arrays (one per axis),</span>
<span class="sd">        - A mix of scalars and arrays (broadcast-compatible).</span>

<span class="sd">        If `field_axes` is provided, `varargs` must match its length. If `axes` is not provided, then `varargs` should</span>
<span class="sd">        be ``tensor_field.ndim - rank`` in length (or be a scalar).</span>
<span class="sd">    field_axes : list of int, optional</span>
<span class="sd">        The spatial axes over which to compute the component-wise partial derivatives. If `field_axes` is</span>
<span class="sd">        not specified, then all ``tensor_field.ndim - rank`` axes are computed.</span>
<span class="sd">    output_indices : list of int, optional</span>
<span class="sd">        Explicit mapping from each axis listed in `field_axes` to the indices in the output&#39;s</span>
<span class="sd">        final dimension of size ``ndim``. This parameter allows precise control over the placement</span>
<span class="sd">        of computed gradients within the output array.</span>

<span class="sd">        If provided, `output_indices` must have the same length as `field_axes`.</span>
<span class="sd">        Each computed gradient along the spatial axis ``field_axes[i]`` will be stored at index</span>
<span class="sd">        ``output_indices[i]`` in the last dimension of the output.</span>

<span class="sd">        If omitted, the default behavior is ``output_indices = field_axes``, i.e., gradients are</span>
<span class="sd">        placed in the output slot corresponding to their source axis.</span>

<span class="sd">        .. note::</span>
<span class="sd">            All positions in the final axis of the output array not listed in ``output_indices``</span>
<span class="sd">            are left unmodified (typically zero-filled unless ``out`` was pre-populated).</span>
<span class="sd">    edge_order : {1, 2}, optional</span>
<span class="sd">        Gradient is calculated using N-th order accurate differences</span>
<span class="sd">        at the boundaries. Default: 1.</span>
<span class="sd">    out : numpy.ndarray, optional</span>
<span class="sd">        Buffer in which to store the output to preserve memory. If provided, `out` must have shape</span>
<span class="sd">        ``tensor_field.shape + (ndim,)``. If `out` is not specified, then it is allocated during the</span>
<span class="sd">        function call.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    numpy.gradient: The computational backend for this operation.</span>
<span class="sd">    dense_gradient_contravariant_full: Contravariant gradient for full metric.</span>
<span class="sd">    dense_gradient_contravariant_diag: Contravariant gradient for diagonal metric.</span>
<span class="sd">    dense_gradient: Wrapper for user-facing gradient computations.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    In a simple 1-D case, we can use this function to compute the gradient.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pymetric.differential_geometry.dense_ops import (</span>
<span class="sd">    ...     dense_gradient_covariant,</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; x = np.linspace(0, 4, 5)          #  [0, 1, 2, 3, 4]</span>
<span class="sd">    &gt;&gt;&gt; f = x**2                          #  [0, 1, 4, 9, 16]</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; grad_cov = dense_gradient_covariant(f, 0, 1, 1.0)          # dx = 1</span>
<span class="sd">    &gt;&gt;&gt; grad_cov</span>
<span class="sd">    array([[0.],</span>
<span class="sd">           [2.],</span>
<span class="sd">           [4.],</span>
<span class="sd">           [6.],</span>
<span class="sd">           [8.]])</span>

<span class="sd">    In a more complicated 2-D case, the call sequence still looks the same.</span>

<span class="sd">    .. plot::</span>
<span class="sd">        :include-source:</span>

<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; from pymetric.differential_geometry.dense_ops import dense_gradient_covariant</span>
<span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; x = np.linspace(-1,1,100)</span>
<span class="sd">        &gt;&gt;&gt; y = np.linspace(-1,1,100)</span>
<span class="sd">        &gt;&gt;&gt; X,Y = np.meshgrid(x,y)</span>
<span class="sd">        &gt;&gt;&gt; Z = np.sin(X**2 + Y**2)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; grad = dense_gradient_covariant(Z,0,2,x,y)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; fig,axes = plt.subplots(2,2,sharex=True,sharey=True)</span>
<span class="sd">        &gt;&gt;&gt; axes[0,1].set_visible(False)</span>
<span class="sd">        &gt;&gt;&gt; _ = axes[0,0].imshow(Z.T, origin=&#39;lower&#39;, vmin=-1,vmax=1,extent=(-1,1,-1,1))</span>
<span class="sd">        &gt;&gt;&gt; _ = axes[1,0].imshow(grad[...,0].T, origin=&#39;lower&#39;, vmin=-1,vmax=1,extent=(-1,1,-1,1))</span>
<span class="sd">        &gt;&gt;&gt; _ = axes[1,1].imshow(grad[...,1].T, origin=&#39;lower&#39;, vmin=-1,vmax=1,extent=(-1,1,-1,1))</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.show()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Coerce the axes so that we know how many</span>
    <span class="c1"># axes we are actually computing derivatives for.</span>
    <span class="c1"># Ensure we don&#39;t have an invalid number of axes.</span>
    <span class="n">t_shape</span><span class="p">,</span> <span class="n">t_ndim</span> <span class="o">=</span> <span class="n">tensor_field</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">tensor_field</span><span class="o">.</span><span class="n">ndim</span>
    <span class="k">if</span> <span class="n">field_axes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_number_of_axes</span> <span class="o">=</span> <span class="n">t_ndim</span> <span class="o">-</span> <span class="n">rank</span>
        <span class="n">field_axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">t_ndim</span> <span class="o">-</span> <span class="n">rank</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_number_of_axes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">field_axes</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">_number_of_axes</span> <span class="o">&gt;</span> <span class="n">ndim</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Number of grid axes (</span><span class="si">{</span><span class="n">_number_of_axes</span><span class="si">}</span><span class="s2">) must be &lt;= the &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;number of dimensions </span><span class="si">{</span><span class="n">ndim</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Setup the output indices.</span>
    <span class="k">if</span> <span class="n">output_indices</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">_number_of_axes</span><span class="p">)</span>

    <span class="c1"># Fix the varargs if the are length 1 so</span>
    <span class="c1"># that we never have an issue with broadcasting.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">varargs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">varargs</span> <span class="o">*=</span> <span class="n">_number_of_axes</span>

    <span class="c1"># Allocate the output array. This should be the</span>
    <span class="c1"># same shape as tensor_field but with _number_of_axes elements</span>
    <span class="c1"># in an additional</span>
    <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">t_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">ndim</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor_field</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>

    <span class="c1"># Now iterate through each of the axes and</span>
    <span class="c1"># perform the differentiation procedure. We then assign</span>
    <span class="c1"># each into the out buffer.</span>
    <span class="k">for</span> <span class="n">_i</span><span class="p">,</span> <span class="p">(</span><span class="n">fax</span><span class="p">,</span> <span class="n">oax</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">field_axes</span><span class="p">,</span> <span class="n">output_indices</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">t_shape</span><span class="p">[</span><span class="n">fax</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">edge_order</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Failed to compute a gradient along axis </span><span class="si">{</span><span class="n">fax</span><span class="si">}</span><span class="s2"> because its shape was smaller than `edge_order`.&quot;</span>
            <span class="p">)</span>
        <span class="n">out</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">oax</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
            <span class="n">tensor_field</span><span class="p">,</span> <span class="n">varargs</span><span class="p">[</span><span class="n">_i</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">fax</span><span class="p">,</span> <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">out</span></div>



<div class="viewcode-block" id="dense_gradient_contravariant_full">
<a class="viewcode-back" href="../../_as_gen/differential_geometry.dense_ops.dense_gradient_contravariant_full.html#differential_geometry.dense_ops.dense_gradient_contravariant_full">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">dense_gradient_contravariant_full</span><span class="p">(</span>
    <span class="n">tensor_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">inverse_metric_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">ndim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
    <span class="n">field_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_indices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_order</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the contravariant gradient :math:`\nabla^\mu T^{\dots}` using the inverse metric tensor.</span>

<span class="sd">    This function computes the covariant (partial) derivatives of a tensor field and then raises</span>
<span class="sd">    the newly introduced index using the inverse metric:</span>

<span class="sd">    .. math::</span>

<span class="sd">        (\nabla^\mu T^{\dots}) = g^{\mu\nu} \partial_\nu T^{\dots}</span>

<span class="sd">    The result has one additional tensor index appended (contravariant index from differentiation).</span>

<span class="sd">    .. warning::</span>
<span class="sd">        This is a low-level routine and does **not** validate input shapes or metric consistency.</span>
<span class="sd">        It assumes all inputs are correctly broadcast and aligned.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor_field : numpy.ndarray</span>
<span class="sd">        Tensor field of shape ``(F_1, ..., F_m, N, ...)``, where the last `rank` axes</span>
<span class="sd">        are the tensor index dimensions. The partial derivatives are computed over the first `m` axes.</span>

<span class="sd">        .. hint::</span>

<span class="sd">            Because this function is a low-level callable, it does not enforce the density of</span>
<span class="sd">            the elements in the trailing dimensions of the field. This can be used in some cases where</span>
<span class="sd">            the field is not **technically** a tensor field.</span>

<span class="sd">    inverse_metric_field : numpy.ndarray</span>
<span class="sd">        Inverse metric tensor with shape ``(..., ndim, ndim)``,</span>
<span class="sd">        where the leading dimensions (denoted here as ``F1, ..., F_n``) must be broadcast-compatible</span>
<span class="sd">        with the grid (spatial) portion of `tensor_field`.</span>

<span class="sd">        Specifically, if `tensor_field` has shape ``(S1, ..., S_m, I1, ..., I_rank)``,</span>
<span class="sd">        then `inverse_metric_field` must be broadcast-compatible with ``(S1, ..., S_m)``.</span>
<span class="sd">        The last two dimensions must be exactly ``(ndim, ndim)``, representing the inverse metric</span>
<span class="sd">        at each grid point.</span>
<span class="sd">    rank : int</span>
<span class="sd">        Number of trailing axes that represent tensor indices (i.e., tensor rank). The `rank` determines</span>
<span class="sd">        the number of identified coordinate axes and therefore determines the shape of the returned array.</span>
<span class="sd">    ndim: int</span>
<span class="sd">        The number of total dimensions in the relevant coordinate system. This determines the maximum allowed value</span>
<span class="sd">        for ``m`` and the number of elements in the trailing dimension of the output.</span>
<span class="sd">    *varargs :</span>
<span class="sd">        Grid spacing for each spatial axis. Follows the same format as :func:`numpy.gradient`, and can be:</span>

<span class="sd">        - A single scalar (applied to all spatial axes),</span>
<span class="sd">        - A list of scalars (one per axis),</span>
<span class="sd">        - A list of coordinate arrays (one per axis),</span>
<span class="sd">        - A mix of scalars and arrays (broadcast-compatible).</span>

<span class="sd">        If `field_axes` is provided, `varargs` must match its length. If `axes` is not provided, then `varargs` should</span>
<span class="sd">        be ``tensor_field.ndim - rank`` in length (or be a scalar).</span>
<span class="sd">    field_axes : list of int, optional</span>
<span class="sd">        The spatial axes over which to compute the component-wise partial derivatives. If `field_axes` is</span>
<span class="sd">        not specified, then all ``tensor_field.ndim - rank`` axes are computed.</span>
<span class="sd">    output_indices : list of int, optional</span>
<span class="sd">        Explicit mapping from each axis listed in `field_axes` to the indices in the output&#39;s</span>
<span class="sd">        final dimension of size ``ndim``. This parameter allows precise control over the placement</span>
<span class="sd">        of computed gradients within the output array.</span>

<span class="sd">        If provided, `output_indices` must have the same length as `field_axes`.</span>
<span class="sd">        Each computed gradient along the spatial axis ``field_axes[i]`` will be stored at index</span>
<span class="sd">        ``output_indices[i]`` in the last dimension of the output.</span>

<span class="sd">        If omitted, the default behavior is ``output_indices = field_axes``, i.e., gradients are</span>
<span class="sd">        placed in the output slot corresponding to their source axis.</span>

<span class="sd">        .. note::</span>
<span class="sd">            All positions in the final axis of the output array not listed in ``output_indices``</span>
<span class="sd">            are left unmodified (typically zero-filled unless ``out`` was pre-populated).</span>
<span class="sd">    edge_order : {1, 2}, optional</span>
<span class="sd">        Gradient is calculated using N-th order accurate differences</span>
<span class="sd">        at the boundaries. Default: 1.</span>
<span class="sd">    out : numpy.ndarray, optional</span>
<span class="sd">        Buffer in which to store the output to preserve memory. If provided, `out` must have shape</span>
<span class="sd">        ``tensor_field.shape + (ndim,)``. If `out` is not specified, then it is allocated during the</span>
<span class="sd">        function call.</span>
<span class="sd">    **kwargs :</span>
<span class="sd">        Additional keyword arguments passed to :func:`numpy.einsum` for the metric contraction.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray</span>
<span class="sd">        The contravariant gradient of the input tensor field, with shape ``B + (ndim,)``,</span>
<span class="sd">        where ``B`` is the broadcasted shape of the spatial portion of `tensor_field`</span>
<span class="sd">        and `inverse_metric_field`.</span>

<span class="sd">        This result represents the gradient with the differentiation index raised by the inverse metric,</span>
<span class="sd">        and the final axis of size ``ndim`` corresponds to the contravariant coordinate direction</span>
<span class="sd">        of the derivative at each point.</span>


<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    numpy.gradient: The computational backend for this operation.</span>
<span class="sd">    dense_gradient_covariant: Contravariant gradient for full metric.</span>
<span class="sd">    dense_gradient_contravariant_diag: Contravariant gradient for diagonal metric.</span>
<span class="sd">    dense_gradient: Wrapper for user-facing gradient computations.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    In effect, this function calls :func:`dense_gradient_covariant` to compute the covariant gradient</span>
<span class="sd">    and then contracts the result with the metric.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pymetric.differential_geometry.dense_ops import (</span>
<span class="sd">    ...     dense_gradient_contravariant_full,</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; x = np.linspace(0, 4, 5)          #  [0, 1, 2, 3, 4]</span>
<span class="sd">    &gt;&gt;&gt; f = x**2                          #  [0, 1, 4, 9, 16]</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; inv_metric_full = np.ones((f.size, 1, 1))   # shape broadcast‑compatible with grad_cov</span>
<span class="sd">    &gt;&gt;&gt; grad_contra_full = dense_gradient_contravariant_full(</span>
<span class="sd">    ...     f, inv_metric_full,0 , 1, 1.0)</span>
<span class="sd">    &gt;&gt;&gt; grad_contra_full</span>
<span class="sd">    array([[0.],</span>
<span class="sd">           [2.],</span>
<span class="sd">           [4.],</span>
<span class="sd">           [6.],</span>
<span class="sd">           [8.]])</span>

<span class="sd">    As a more advanced example, let&#39;s look at the co. versus contra. components of a gradient case:</span>

<span class="sd">    .. plot::</span>
<span class="sd">        :include-source:</span>

<span class="sd">        &gt;&gt;&gt; from scipy.interpolate import RegularGridInterpolator</span>
<span class="sd">        &gt;&gt;&gt; from pymetric.differential_geometry.dense_ops import (dense_gradient_contravariant_full,</span>
<span class="sd">        ... dense_gradient_covariant)</span>
<span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create the coordinates, the field, and the</span>
<span class="sd">        &gt;&gt;&gt; # interpolators.</span>
<span class="sd">        &gt;&gt;&gt; r = np.linspace(1e-4,1,1000)</span>
<span class="sd">        &gt;&gt;&gt; theta = np.linspace(0,np.pi,30)</span>
<span class="sd">        &gt;&gt;&gt; R,THETA = np.meshgrid(r,theta,indexing=&#39;ij&#39;)</span>
<span class="sd">        &gt;&gt;&gt; Z = np.sin(10*R) * np.cos(THETA)**2</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Build a 1D interpolator for Z.</span>
<span class="sd">        &gt;&gt;&gt; interpZ = RegularGridInterpolator((r,theta),Z,bounds_error=False)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Compute the gradients of Z</span>
<span class="sd">        &gt;&gt;&gt; gradZ = dense_gradient_covariant(Z,0,2,r,theta)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create the metric</span>
<span class="sd">        &gt;&gt;&gt; metric = np.zeros(R.shape + (2,2))</span>
<span class="sd">        &gt;&gt;&gt; metric[:,:,0,0] = 1</span>
<span class="sd">        &gt;&gt;&gt; metric[:,:,1,1] = 1/R**2</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Compute the contravariant gradient.</span>
<span class="sd">        &gt;&gt;&gt; gradZcontra = dense_gradient_contravariant_full(Z,metric,0,2,r,theta)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Build interpolators for the 2 gradient components.</span>
<span class="sd">        &gt;&gt;&gt; interpZr = RegularGridInterpolator((r,theta),gradZ[...,0],bounds_error=False)</span>
<span class="sd">        &gt;&gt;&gt; interpZtheta = RegularGridInterpolator((r,theta),gradZ[...,1],bounds_error=False)</span>
<span class="sd">        &gt;&gt;&gt; interpCZr = RegularGridInterpolator((r,theta),gradZcontra[...,0],bounds_error=False)</span>
<span class="sd">        &gt;&gt;&gt; interpCZtheta = RegularGridInterpolator((r,theta),gradZcontra[...,1],bounds_error=False)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Construct an X/Y grid.</span>
<span class="sd">        &gt;&gt;&gt; bound = 1/np.sqrt(2)</span>
<span class="sd">        &gt;&gt;&gt; x,y = np.linspace(-bound,bound,100),np.linspace(-bound,bound,100)</span>
<span class="sd">        &gt;&gt;&gt; X,Y = np.meshgrid(x,y,indexing=&#39;ij&#39;)</span>
<span class="sd">        &gt;&gt;&gt; RG = np.sqrt(X**2+Y**2)</span>
<span class="sd">        &gt;&gt;&gt; THETAG = np.arccos(Y/RG)</span>
<span class="sd">        &gt;&gt;&gt; grid_points = np.stack([RG.ravel(),THETAG.ravel()],axis=1)</span>
<span class="sd">        &gt;&gt;&gt; Zgrid = interpZ(grid_points).reshape(RG.shape)</span>
<span class="sd">        &gt;&gt;&gt; Zrgrid = interpZr(grid_points).reshape(RG.shape)</span>
<span class="sd">        &gt;&gt;&gt; Zthetagrid = interpZtheta(grid_points).reshape(RG.shape)</span>
<span class="sd">        &gt;&gt;&gt; ZCrgrid = interpCZr(grid_points).reshape(RG.shape)</span>
<span class="sd">        &gt;&gt;&gt; ZCthetagrid = interpCZtheta(grid_points).reshape(RG.shape)</span>

<span class="sd">        &gt;&gt;&gt; # Setup the figure.</span>
<span class="sd">        &gt;&gt;&gt; fig,axes = plt.subplots(2,2, sharex=True, sharey=True)</span>
<span class="sd">        &gt;&gt;&gt; _ = axes[0,0].imshow(Zrgrid.T    ,extent=[-bound,bound,-bound,bound], vmin=-3,vmax=3,cmap=&#39;seismic&#39;,origin=&#39;lower&#39;)</span>
<span class="sd">        &gt;&gt;&gt; _ = axes[0,1].imshow(Zthetagrid.T,extent=[-bound,bound,-bound,bound], vmin=-3,vmax=3,cmap=&#39;seismic&#39;,origin=&#39;lower&#39;)</span>
<span class="sd">        &gt;&gt;&gt; _ = axes[1,0].imshow(ZCrgrid.T    ,extent=[-bound,bound,-bound,bound],vmin=-3,vmax=3,cmap=&#39;seismic&#39;,origin=&#39;lower&#39;)</span>
<span class="sd">        &gt;&gt;&gt; P = axes[1,1].imshow(ZCthetagrid.T,extent=[-bound,bound,-bound,bound],vmin=-3,vmax=3,cmap=&#39;seismic&#39;,origin=&#39;lower&#39;)</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.colorbar(P,ax=axes)</span>
<span class="sd">        &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Determine the broadcasted base shape (excluding trailing index dimensions)</span>
    <span class="n">tensor_base_shape</span> <span class="o">=</span> <span class="n">tensor_field</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">metric_base_shape</span> <span class="o">=</span> <span class="n">inverse_metric_field</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>  <span class="c1"># exclude (ndim, ndim)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">broadcast_shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_shapes</span><span class="p">(</span><span class="n">tensor_base_shape</span><span class="p">,</span> <span class="n">metric_base_shape</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Cannot broadcast tensor_field.shape=</span><span class="si">{</span><span class="n">tensor_base_shape</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;with inverse_metric_field.shape=</span><span class="si">{</span><span class="n">metric_base_shape</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

    <span class="c1"># Allocate output buffer if not provided</span>
    <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">broadcast_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">ndim</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor_field</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">expected_shape</span> <span class="o">=</span> <span class="n">broadcast_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">ndim</span><span class="p">,)</span>
        <span class="k">if</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">expected_shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Provided `out` has shape </span><span class="si">{</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, but expected </span><span class="si">{</span><span class="n">expected_shape</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;from broadcasting tensor field and inverse metric.&quot;</span>
            <span class="p">)</span>

    <span class="c1"># Compute the covariant gradient into the broadcasted output buffer</span>
    <span class="n">dense_gradient_covariant</span><span class="p">(</span>
        <span class="n">tensor_field</span><span class="p">,</span>
        <span class="n">rank</span><span class="p">,</span>
        <span class="n">ndim</span><span class="p">,</span>
        <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
        <span class="n">field_axes</span><span class="o">=</span><span class="n">field_axes</span><span class="p">,</span>
        <span class="n">output_indices</span><span class="o">=</span><span class="n">output_indices</span><span class="p">,</span>
        <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
        <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Contract the covariant gradient with the inverse metric to raise the index</span>
    <span class="k">return</span> <span class="n">_dense_contract_index_with_metric</span><span class="p">(</span>
        <span class="n">out</span><span class="p">,</span>
        <span class="n">inverse_metric_field</span><span class="p">,</span>
        <span class="n">index</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
        <span class="n">rank</span><span class="o">=</span><span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="dense_gradient_contravariant_diag">
<a class="viewcode-back" href="../../_as_gen/differential_geometry.dense_ops.dense_gradient_contravariant_diag.html#differential_geometry.dense_ops.dense_gradient_contravariant_diag">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">dense_gradient_contravariant_diag</span><span class="p">(</span>
    <span class="n">tensor_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">inverse_metric_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">ndim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
    <span class="n">field_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_indices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_order</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="o">**</span><span class="n">_</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the contravariant gradient :math:`\nabla^\mu T^{\dots}` of a tensor field</span>
<span class="sd">    using a diagonal inverse metric tensor.</span>

<span class="sd">    This function computes the covariant partial derivatives over the field dimensions,</span>
<span class="sd">    then raises the newly introduced index using the provided diagonal inverse metric:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \nabla^\mu T^{\dots} = g^{\mu\mu} \partial_\mu T^{\dots}</span>

<span class="sd">    No summation is implied since the metric is diagonal.</span>

<span class="sd">    .. warning::</span>
<span class="sd">        This is a low-level routine and does **not** validate input shapes or consistency.</span>
<span class="sd">        It assumes all inputs are correctly broadcast and aligned.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor_field : numpy.ndarray</span>
<span class="sd">        Tensor field of shape ``(F_1, ..., F_m, N, ...)``, where the last `rank` axes</span>
<span class="sd">        are the tensor index dimensions. The partial derivatives are computed over the first `m` axes.</span>

<span class="sd">        .. hint::</span>

<span class="sd">            Because this function is a low-level callable, it does not enforce the density of</span>
<span class="sd">            the elements in the trailing dimensions of the field. This can be used in some cases where</span>
<span class="sd">            the field is not **technically** a tensor field.</span>

<span class="sd">    inverse_metric_field : numpy.ndarray</span>
<span class="sd">        Inverse metric tensor with shape ``(..., ndim, )``,</span>
<span class="sd">        where the leading dimensions (denoted here as ``F1, ..., F_n``) must be broadcast-compatible</span>
<span class="sd">        with the grid (spatial) portion of `tensor_field`.</span>

<span class="sd">        Specifically, if `tensor_field` has shape ``(S1, ..., S_m, I1, ..., I_rank)``,</span>
<span class="sd">        then `inverse_metric_field` must be broadcast-compatible with ``(S1, ..., S_m)``.</span>
<span class="sd">        The last dimension must be exactly ``(ndim,)``, representing the inverse metric</span>
<span class="sd">        at each grid point.</span>
<span class="sd">    rank : int</span>
<span class="sd">        Number of trailing axes that represent tensor indices (i.e., tensor rank). The `rank` determines</span>
<span class="sd">        the number of identified coordinate axes and therefore determines the shape of the returned array.</span>
<span class="sd">    ndim: int</span>
<span class="sd">        The number of total dimensions in the relevant coordinate system. This determines the maximum allowed value</span>
<span class="sd">        for ``m`` and the number of elements in the trailing dimension of the output.</span>
<span class="sd">    *varargs :</span>
<span class="sd">        Grid spacing for each spatial axis. Follows the same format as :func:`numpy.gradient`, and can be:</span>

<span class="sd">        - A single scalar (applied to all spatial axes),</span>
<span class="sd">        - A list of scalars (one per axis),</span>
<span class="sd">        - A list of coordinate arrays (one per axis),</span>
<span class="sd">        - A mix of scalars and arrays (broadcast-compatible).</span>

<span class="sd">        If `field_axes` is provided, `varargs` must match its length. If `axes` is not provided, then `varargs` should</span>
<span class="sd">        be ``tensor_field.ndim - rank`` in length (or be a scalar).</span>
<span class="sd">    field_axes : list of int, optional</span>
<span class="sd">        The spatial axes over which to compute the component-wise partial derivatives. If `field_axes` is</span>
<span class="sd">        not specified, then all ``tensor_field.ndim - rank`` axes are computed.</span>
<span class="sd">    output_indices : list of int, optional</span>
<span class="sd">        Explicit mapping from each axis listed in `field_axes` to the indices in the output&#39;s</span>
<span class="sd">        final dimension of size ``ndim``. This parameter allows precise control over the placement</span>
<span class="sd">        of computed gradients within the output array.</span>

<span class="sd">        If provided, `output_indices` must have the same length as `field_axes`.</span>
<span class="sd">        Each computed gradient along the spatial axis ``field_axes[i]`` will be stored at index</span>
<span class="sd">        ``output_indices[i]`` in the last dimension of the output.</span>

<span class="sd">        If omitted, the default behavior is ``output_indices = field_axes``, i.e., gradients are</span>
<span class="sd">        placed in the output slot corresponding to their source axis.</span>

<span class="sd">        .. note::</span>
<span class="sd">            All positions in the final axis of the output array not listed in ``output_indices``</span>
<span class="sd">            are left unmodified (typically zero-filled unless ``out`` was pre-populated).</span>
<span class="sd">    edge_order : {1, 2}, optional</span>
<span class="sd">        Gradient is calculated using N-th order accurate differences</span>
<span class="sd">        at the boundaries. Default: 1.</span>
<span class="sd">    out : numpy.ndarray, optional</span>
<span class="sd">        Buffer in which to store the output to preserve memory. If provided, `out` must have shape</span>
<span class="sd">        ``tensor_field.shape + (ndim,)``. If `out` is not specified, then it is allocated during the</span>
<span class="sd">        function call.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray</span>
<span class="sd">        The contravariant gradient of the input tensor field, with shape ``B + (ndim,)``,</span>
<span class="sd">        where ``B`` is the broadcasted shape of the spatial portion of `tensor_field`</span>
<span class="sd">        and `inverse_metric_field`.</span>

<span class="sd">        This result represents the gradient with the differentiation index raised by the inverse metric,</span>
<span class="sd">        and the final axis of size ``ndim`` corresponds to the contravariant coordinate direction</span>
<span class="sd">        of the derivative at each point.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    numpy.gradient: The computational backend for this operation.</span>
<span class="sd">    dense_gradient_covariant: Contravariant gradient for full metric.</span>
<span class="sd">    dense_gradient_contravariant_full: Contravariant gradient for full metric.</span>
<span class="sd">    dense_gradient: Wrapper for user-facing gradient computations.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    As a more advanced example, let&#39;s look at the co. versus contra. components of a gradient case:</span>

<span class="sd">    .. plot::</span>
<span class="sd">        :include-source:</span>

<span class="sd">        &gt;&gt;&gt; # ------------------------------------------------------------------</span>
<span class="sd">        &gt;&gt;&gt; # 0)  Set up a toy scalar field  f(r) = sin(r/r_0) cos^2(theta)</span>
<span class="sd">        &gt;&gt;&gt; # ------------------------------------------------------------------</span>
<span class="sd">        &gt;&gt;&gt; from scipy.interpolate import RegularGridInterpolator</span>
<span class="sd">        &gt;&gt;&gt; from pymetric.differential_geometry.dense_ops import (dense_gradient_contravariant_diag,</span>
<span class="sd">        ... dense_gradient_covariant)</span>
<span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">        &gt;&gt;&gt; r = np.linspace(1e-4,1,1000)</span>
<span class="sd">        &gt;&gt;&gt; theta = np.linspace(0,np.pi,30)</span>
<span class="sd">        &gt;&gt;&gt; R,THETA = np.meshgrid(r,theta,indexing=&#39;ij&#39;)</span>
<span class="sd">        &gt;&gt;&gt; Z = np.sin(10*R) * np.cos(THETA)**2</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Build a 1D interpolator for Z.</span>
<span class="sd">        &gt;&gt;&gt; interpZ = RegularGridInterpolator((r,theta),Z,bounds_error=False)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Compute the gradients of Z</span>
<span class="sd">        &gt;&gt;&gt; gradZ = dense_gradient_covariant(Z,0,2,r,theta)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create the metric</span>
<span class="sd">        &gt;&gt;&gt; metric = np.zeros(R.shape + (2,))</span>
<span class="sd">        &gt;&gt;&gt; metric[:,:,0,] = 1</span>
<span class="sd">        &gt;&gt;&gt; metric[:,:,1,] = 1/R**2</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Compute the contravariant gradient.</span>
<span class="sd">        &gt;&gt;&gt; gradZcontra = dense_gradient_contravariant_diag(Z,metric,0,2,r,theta)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Build interpolators for the 2 gradient components.</span>
<span class="sd">        &gt;&gt;&gt; interpZr = RegularGridInterpolator((r,theta),gradZ[...,0],bounds_error=False)</span>
<span class="sd">        &gt;&gt;&gt; interpZtheta = RegularGridInterpolator((r,theta),gradZ[...,1],bounds_error=False)</span>
<span class="sd">        &gt;&gt;&gt; interpCZr = RegularGridInterpolator((r,theta),gradZcontra[...,0],bounds_error=False)</span>
<span class="sd">        &gt;&gt;&gt; interpCZtheta = RegularGridInterpolator((r,theta),gradZcontra[...,1],bounds_error=False)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Construct an X/Y grid.</span>
<span class="sd">        &gt;&gt;&gt; bound = 1/np.sqrt(2)</span>
<span class="sd">        &gt;&gt;&gt; x,y = np.linspace(-bound,bound,100),np.linspace(-bound,bound,100)</span>
<span class="sd">        &gt;&gt;&gt; X,Y = np.meshgrid(x,y,indexing=&#39;ij&#39;)</span>
<span class="sd">        &gt;&gt;&gt; RG = np.sqrt(X**2+Y**2)</span>
<span class="sd">        &gt;&gt;&gt; THETAG = np.arccos(Y/RG)</span>
<span class="sd">        &gt;&gt;&gt; grid_points = np.stack([RG.ravel(),THETAG.ravel()],axis=1)</span>
<span class="sd">        &gt;&gt;&gt; Zgrid = interpZ(grid_points).reshape(RG.shape)</span>
<span class="sd">        &gt;&gt;&gt; Zrgrid = interpZr(grid_points).reshape(RG.shape)</span>
<span class="sd">        &gt;&gt;&gt; Zthetagrid = interpZtheta(grid_points).reshape(RG.shape)</span>
<span class="sd">        &gt;&gt;&gt; ZCrgrid = interpCZr(grid_points).reshape(RG.shape)</span>
<span class="sd">        &gt;&gt;&gt; ZCthetagrid = interpCZtheta(grid_points).reshape(RG.shape)</span>

<span class="sd">        &gt;&gt;&gt; # Setup the figure.</span>
<span class="sd">        &gt;&gt;&gt; fig,axes = plt.subplots(2,2, sharex=True, sharey=True)</span>
<span class="sd">        &gt;&gt;&gt; _ = axes[0,0].imshow(Zrgrid.T    ,extent=[-bound,bound,-bound,bound], vmin=-3,vmax=3,cmap=&#39;seismic&#39;,origin=&#39;lower&#39;)</span>
<span class="sd">        &gt;&gt;&gt; _ = axes[0,1].imshow(Zthetagrid.T,extent=[-bound,bound,-bound,bound], vmin=-3,vmax=3,cmap=&#39;seismic&#39;,origin=&#39;lower&#39;)</span>
<span class="sd">        &gt;&gt;&gt; _ = axes[1,0].imshow(ZCrgrid.T    ,extent=[-bound,bound,-bound,bound],vmin=-3,vmax=3,cmap=&#39;seismic&#39;,origin=&#39;lower&#39;)</span>
<span class="sd">        &gt;&gt;&gt; P = axes[1,1].imshow(ZCthetagrid.T,extent=[-bound,bound,-bound,bound],vmin=-3,vmax=3,cmap=&#39;seismic&#39;,origin=&#39;lower&#39;)</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.colorbar(P,ax=axes)</span>
<span class="sd">        &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Determine the broadcasted base shape (excluding trailing index dimensions)</span>
    <span class="n">tensor_base_shape</span> <span class="o">=</span> <span class="n">tensor_field</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">metric_base_shape</span> <span class="o">=</span> <span class="n">inverse_metric_field</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># exclude (ndim, ndim)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">broadcast_shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_shapes</span><span class="p">(</span><span class="n">tensor_base_shape</span><span class="p">,</span> <span class="n">metric_base_shape</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Cannot broadcast tensor_field.shape=</span><span class="si">{</span><span class="n">tensor_base_shape</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;with inverse_metric_field.shape=</span><span class="si">{</span><span class="n">metric_base_shape</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>

    <span class="c1"># Allocate output buffer if not provided</span>
    <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">broadcast_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">ndim</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor_field</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">expected_shape</span> <span class="o">=</span> <span class="n">broadcast_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">ndim</span><span class="p">,)</span>
        <span class="k">if</span> <span class="n">out</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">expected_shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Provided `out` has shape </span><span class="si">{</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, but expected </span><span class="si">{</span><span class="n">expected_shape</span><span class="si">}</span><span class="s2"> &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;from broadcasting tensor field and inverse metric.&quot;</span>
            <span class="p">)</span>

    <span class="c1"># Compute the covariant gradient into the broadcasted output buffer</span>
    <span class="n">dense_gradient_covariant</span><span class="p">(</span>
        <span class="n">tensor_field</span><span class="p">,</span>
        <span class="n">rank</span><span class="p">,</span>
        <span class="n">ndim</span><span class="p">,</span>
        <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
        <span class="n">field_axes</span><span class="o">=</span><span class="n">field_axes</span><span class="p">,</span>
        <span class="n">output_indices</span><span class="o">=</span><span class="n">output_indices</span><span class="p">,</span>
        <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
        <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Contract the covariant gradient with the inverse metric to raise the index</span>
    <span class="k">return</span> <span class="n">_dense_contract_index_with_diagonal_metric</span><span class="p">(</span>
        <span class="n">out</span><span class="p">,</span>
        <span class="n">inverse_metric_field</span><span class="p">,</span>
        <span class="n">index</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span>
        <span class="n">rank</span><span class="o">=</span><span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="dense_gradient">
<a class="viewcode-back" href="../../_as_gen/differential_geometry.dense_ops.dense_gradient.html#differential_geometry.dense_ops.dense_gradient">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">dense_gradient</span><span class="p">(</span>
    <span class="n">tensor_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">ndim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
    <span class="n">basis</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;contravariant&quot;</span><span class="p">,</span> <span class="s2">&quot;covariant&quot;</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;covariant&quot;</span><span class="p">,</span>
    <span class="n">inverse_metric_field</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_order</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">field_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_indices</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the gradient of a tensor field in the specified output basis.</span>

<span class="sd">    This function computes the component-wise partial derivatives of a tensor field with respect</span>
<span class="sd">    to its grid coordinates, and optionally raises the resulting index using a provided inverse metric.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor_field : numpy.ndarray</span>
<span class="sd">        Tensor field of shape ``(F_1, ..., F_m, N, ...)``, where the last `rank` axes</span>
<span class="sd">        are the tensor index dimensions. The partial derivatives are computed over the first `m` axes.</span>

<span class="sd">        .. hint::</span>

<span class="sd">            Because this function is a low-level callable, it does not enforce the density of</span>
<span class="sd">            the elements in the trailing dimensions of the field. This can be used in some cases where</span>
<span class="sd">            the field is not **technically** a tensor field.</span>

<span class="sd">    rank : int</span>
<span class="sd">        Number of trailing axes that represent tensor indices (i.e., tensor rank). The `rank` determines</span>
<span class="sd">        the number of identified coordinate axes and therefore determines the shape of the returned array.</span>
<span class="sd">    ndim: int</span>
<span class="sd">        The number of total dimensions in the relevant coordinate system. This determines the maximum allowed value</span>
<span class="sd">        for ``m`` and the number of elements in the trailing dimension of the output.</span>
<span class="sd">    *varargs :</span>
<span class="sd">        Grid spacing for each spatial axis. Follows the same format as :func:`numpy.gradient`, and can be:</span>

<span class="sd">        - A single scalar (applied to all spatial axes),</span>
<span class="sd">        - A list of scalars (one per axis),</span>
<span class="sd">        - A list of coordinate arrays (one per axis),</span>
<span class="sd">        - A mix of scalars and arrays (broadcast-compatible).</span>

<span class="sd">        If `field_axes` is provided, `varargs` must match its length. If `axes` is not provided, then `varargs` should</span>
<span class="sd">        be ``tensor_field.ndim - rank`` in length (or be a scalar).</span>
<span class="sd">    inverse_metric_field : numpy.ndarray</span>
<span class="sd">        Inverse metric tensor with shape ``(..., ndim, )`` or ``(..., ndim, ndim)``,</span>
<span class="sd">        where the leading dimensions (denoted here as ``F1, ..., F_n``) must be broadcast-compatible</span>
<span class="sd">        with the grid (spatial) portion of `tensor_field`.</span>

<span class="sd">        Specifically, if `tensor_field` has shape ``(S1, ..., S_m, I1, ..., I_rank)``,</span>
<span class="sd">        then `inverse_metric_field` must be broadcast-compatible with ``(S1, ..., S_m)``.</span>
<span class="sd">        The last two dimensions must be exactly ``(ndim, ndim)``, representing the inverse metric</span>
<span class="sd">        at each grid point.</span>
<span class="sd">    basis: {&#39;contravariant&#39;, &#39;covariant&#39;}, optional</span>
<span class="sd">        The basis in which to compute the result of the operation.</span>
<span class="sd">    field_axes : list of int, optional</span>
<span class="sd">        The spatial axes over which to compute the component-wise partial derivatives. If `field_axes` is</span>
<span class="sd">        not specified, then all ``tensor_field.ndim - rank`` axes are computed.</span>
<span class="sd">    output_indices : list of int, optional</span>
<span class="sd">        Explicit mapping from each axis listed in `field_axes` to the indices in the output&#39;s</span>
<span class="sd">        final dimension of size ``ndim``. This parameter allows precise control over the placement</span>
<span class="sd">        of computed gradients within the output array.</span>

<span class="sd">        If provided, `output_indices` must have the same length as `field_axes`.</span>
<span class="sd">        Each computed gradient along the spatial axis ``field_axes[i]`` will be stored at index</span>
<span class="sd">        ``output_indices[i]`` in the last dimension of the output.</span>

<span class="sd">        If omitted, the default behavior is ``output_indices = field_axes``, i.e., gradients are</span>
<span class="sd">        placed in the output slot corresponding to their source axis.</span>

<span class="sd">        .. note::</span>
<span class="sd">            All positions in the final axis of the output array not listed in ``output_indices``</span>
<span class="sd">            are left unmodified (typically zero-filled unless ``out`` was pre-populated).</span>
<span class="sd">    edge_order : {1, 2}, optional</span>
<span class="sd">        Gradient is calculated using N-th order accurate differences</span>
<span class="sd">        at the boundaries. Default: 1.</span>
<span class="sd">    out : numpy.ndarray, optional</span>
<span class="sd">        Buffer in which to store the output to preserve memory. If provided, `out` must have shape</span>
<span class="sd">        ``tensor_field.shape + (ndim,)``. If `out` is not specified, then it is allocated during the</span>
<span class="sd">        function call.</span>
<span class="sd">    **kwargs :</span>
<span class="sd">        Additional keyword arguments passed to contraction routines.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ~numpy.ndarray</span>
<span class="sd">        Gradient of the tensor field with shape ``tensor_field.shape + (N,)``.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If input shapes are inconsistent, required metric is missing, or basis is invalid.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    As a demonstration of the difference between covariant and contravariant gradients, let&#39;s consider the</span>
<span class="sd">    gradient in spherical coordinates using the scalar function:</span>

<span class="sd">    .. math::</span>

<span class="sd">        f(r, \theta) = r^2 \sin(\theta)</span>

<span class="sd">    The gradient is computed in both covariant and contravariant bases. In</span>
<span class="sd">    spherical coordinates, the metric tensor is diagonal:</span>

<span class="sd">    .. math::</span>

<span class="sd">        g_{rr} = 1, \quad g_{\theta\theta} = r^2</span>

<span class="sd">    and the inverse metric is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        g^{rr} = 1, \quad g^{\theta\theta} = \frac{1}{r^2}</span>

<span class="sd">    Therefore, the covariant gradient is:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \nabla_i f = \left( \frac{\partial f}{\partial r}, \frac{\partial f}{\partial \theta} \right)</span>

<span class="sd">    and the contravariant gradient is obtained by raising the index:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \nabla^i f = g^{ij} \nabla_j f =</span>
<span class="sd">        \left( \frac{\partial f}{\partial r}, \frac{1}{r^2} \frac{\partial f}{\partial \theta} \right)</span>

<span class="sd">    .. plot::</span>
<span class="sd">        :include-source: True</span>

<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">        &gt;&gt;&gt; from pymetric.differential_geometry.dense_ops import dense_gradient</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Create spherical grid</span>
<span class="sd">        &gt;&gt;&gt; r = np.linspace(0.01, 1.0, 100)</span>
<span class="sd">        &gt;&gt;&gt; theta = np.linspace(0, np.pi, 100)</span>
<span class="sd">        &gt;&gt;&gt; R, THETA = np.meshgrid(r, theta, indexing=&#39;ij&#39;)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Define scalar field f(r, theta) = r^2 * sin(theta)</span>
<span class="sd">        &gt;&gt;&gt; F = R**2 * np.sin(THETA)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Define inverse metric for spherical coordinates</span>
<span class="sd">        &gt;&gt;&gt; IM = np.zeros(R.shape + (2,))</span>
<span class="sd">        &gt;&gt;&gt; IM[..., 0] = 1            # g^rr = 1</span>
<span class="sd">        &gt;&gt;&gt; IM[..., 1] = 1 / R**2     # g^thetatheta = 1/r^2</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Compute gradients</span>
<span class="sd">        &gt;&gt;&gt; grad_cov = dense_gradient(F, 0, 2, r, theta, basis=&#39;covariant&#39;, edge_order=2)</span>
<span class="sd">        &gt;&gt;&gt; grad_contra = dense_gradient(F, 0, 2, r, theta, basis=&#39;contravariant&#39;, inverse_metric_field=IM, edge_order=2)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # Visualize theta component (index 1) of both gradients</span>
<span class="sd">        &gt;&gt;&gt; fig, axes = plt.subplots(1, 2, figsize=(10, 4))</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; im0 = axes[0].imshow(grad_cov[..., 1].T, origin=&#39;lower&#39;, extent=[0.01, 1.0, 0, np.pi], aspect=&#39;auto&#39;)</span>
<span class="sd">        &gt;&gt;&gt; _ = axes[0].set_title(r&#39;Covariant Gradient $(\partial_\theta f)$&#39;)</span>
<span class="sd">        &gt;&gt;&gt; _ = fig.colorbar(im0, ax=axes[0])</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; im1 = axes[1].imshow(grad_contra[..., 1].T, origin=&#39;lower&#39;, extent=[0.01, 1.0, 0, np.pi], aspect=&#39;auto&#39;)</span>
<span class="sd">        &gt;&gt;&gt; _ = axes[1].set_title(r&#39;Contravariant Gradient $(r^{-2} \; \partial_\theta f)$&#39;)</span>
<span class="sd">        &gt;&gt;&gt; _ = fig.colorbar(im1, ax=axes[1])</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; for ax in axes:</span>
<span class="sd">        ...     _ = ax.set_xlabel(&quot;r&quot;)</span>
<span class="sd">        ...     _ = ax.set_ylabel(&quot;theta&quot;)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; plt.tight_layout()</span>
<span class="sd">        &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">tensor_shape</span> <span class="o">=</span> <span class="n">tensor_field</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">tensor_ndim</span> <span class="o">=</span> <span class="n">tensor_field</span><span class="o">.</span><span class="n">ndim</span>

    <span class="k">if</span> <span class="n">rank</span> <span class="o">&gt;</span> <span class="n">tensor_ndim</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Tensor rank cannot exceed the number of dimensions in the array.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Distinguish the basis and proceed to the low-level callable</span>
    <span class="c1"># depending on which basis is specified.</span>
    <span class="k">if</span> <span class="n">basis</span> <span class="o">==</span> <span class="s2">&quot;covariant&quot;</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">dense_gradient_covariant</span><span class="p">(</span>
                <span class="n">tensor_field</span><span class="p">,</span>
                <span class="n">rank</span><span class="p">,</span>
                <span class="n">ndim</span><span class="p">,</span>
                <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
                <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
                <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
                <span class="n">field_axes</span><span class="o">=</span><span class="n">field_axes</span><span class="p">,</span>
                <span class="n">output_indices</span><span class="o">=</span><span class="n">output_indices</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Failed to compute covariant gradient: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="kn">from</span><span class="w"> </span><span class="nn">e</span>
    <span class="k">elif</span> <span class="n">basis</span> <span class="o">==</span> <span class="s2">&quot;contravariant&quot;</span><span class="p">:</span>
        <span class="c1"># Check that the inverse_metric_field is specified before</span>
        <span class="c1"># proceeding.</span>
        <span class="k">if</span> <span class="n">inverse_metric_field</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;`inverse_metric_field` must be provided when `basis=&#39;contravariant&#39;`.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Determine metric type based on shape compatibility</span>
        <span class="n">spatial_shape</span> <span class="o">=</span> <span class="n">tensor_shape</span><span class="p">[:</span> <span class="n">tensor_ndim</span> <span class="o">-</span> <span class="n">rank</span><span class="p">]</span>
        <span class="n">metric_type</span> <span class="o">=</span> <span class="n">infer_metric_type</span><span class="p">(</span><span class="n">inverse_metric_field</span><span class="p">,</span> <span class="n">spatial_shape</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">metric_type</span> <span class="o">==</span> <span class="s2">&quot;full&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">dense_gradient_contravariant_full</span><span class="p">(</span>
                <span class="n">tensor_field</span><span class="p">,</span>
                <span class="n">inverse_metric_field</span><span class="p">,</span>
                <span class="n">rank</span><span class="p">,</span>
                <span class="n">ndim</span><span class="p">,</span>
                <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
                <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
                <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
                <span class="n">field_axes</span><span class="o">=</span><span class="n">field_axes</span><span class="p">,</span>
                <span class="n">output_indices</span><span class="o">=</span><span class="n">output_indices</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">metric_type</span> <span class="o">==</span> <span class="s2">&quot;diagonal&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">dense_gradient_contravariant_diag</span><span class="p">(</span>
                <span class="n">tensor_field</span><span class="p">,</span>
                <span class="n">inverse_metric_field</span><span class="p">,</span>
                <span class="n">rank</span><span class="p">,</span>
                <span class="n">ndim</span><span class="p">,</span>
                <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
                <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
                <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
                <span class="n">field_axes</span><span class="o">=</span><span class="n">field_axes</span><span class="p">,</span>
                <span class="n">output_indices</span><span class="o">=</span><span class="n">output_indices</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unrecognized metric type: </span><span class="si">{</span><span class="n">metric_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;`basis` must be &#39;covariant&#39; or &#39;contravariant&#39;, not &#39;</span><span class="si">{</span><span class="n">basis</span><span class="si">}</span><span class="s2">&#39;.&quot;</span>
        <span class="p">)</span></div>



<span class="c1"># =================================== #</span>
<span class="c1"># Divergence Methods                  #</span>
<span class="c1"># =================================== #</span>
<span class="c1"># These methods are used to compute the divergence of dense</span>
<span class="c1"># tensor fields.</span>
<div class="viewcode-block" id="dense_vector_divergence_contravariant">
<a class="viewcode-back" href="../../_as_gen/differential_geometry.dense_ops.dense_vector_divergence_contravariant.html#differential_geometry.dense_ops.dense_vector_divergence_contravariant">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">dense_vector_divergence_contravariant</span><span class="p">(</span>
    <span class="n">vector_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">Dterm_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
    <span class="n">derivative_field</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">field_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">derivative_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_order</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">_</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the divergence of a contravariant vector field in a general coordinate system using</span>
<span class="sd">    the D-terms and raw partial derivatives.</span>

<span class="sd">    This implements the formula:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \nabla_i V^i = D_i V^i + \partial_i V^i</span>

<span class="sd">    where :math:`D_i = (\partial_i \rho) / \rho` is the logarithmic derivative of the coordinate density.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    vector_field : numpy.ndarray</span>
<span class="sd">        Contravariant vector field with shape ``(F_1, ..., F_M, ndim)``, where the final axis corresponds to coordinate</span>
<span class="sd">        directions. The first ``m`` axes are spatial grid axes. Must be broadcast-compatible with `Dterm_field`.</span>
<span class="sd">    Dterm_field : numpy.ndarray</span>
<span class="sd">        D-term array of shape ``(..., ndim)``, where the last axis matches the number of coordinate directions.</span>
<span class="sd">        Must broadcast with the spatial axes of `vector_field`.</span>
<span class="sd">    *varargs :</span>
<span class="sd">        Grid spacing for each axis. Follows the same format as :func:`numpy.gradient`, and can be:</span>

<span class="sd">        - A single scalar (applied to all spatial axes),</span>
<span class="sd">        - A list of scalars (one per axis),</span>
<span class="sd">        - A list of coordinate arrays (one per axis),</span>
<span class="sd">        - A mix of scalars and arrays (broadcast-compatible).</span>

<span class="sd">        If `derivative_axes` is provided, then `varargs` must match its shape. Otherwise, there must be ``m`` elements</span>
<span class="sd">        in `varargs`.</span>
<span class="sd">    derivative_field : numpy.ndarray, optional</span>
<span class="sd">        Optional array of precomputed partial derivatives of selected vector components.</span>
<span class="sd">        Must have shape broadcast-compatible with the spatial shape of `vector_field`, and a final axis indexing</span>
<span class="sd">        the selected derivative components (same length as `derivative_axes`).</span>
<span class="sd">    field_axes : list of int, optional</span>
<span class="sd">        Maps each grid axis (0 to ``m-1``) to a corresponding component index in the vector field.</span>
<span class="sd">        Defaults to identity mapping ``[0, 1, ..., m-1]``.</span>
<span class="sd">    derivative_axes : list of int, optional</span>
<span class="sd">        Grid axes along which to compute partial derivatives. If not specified, all spatial axes</span>
<span class="sd">        listed in `field_axes` are used.</span>
<span class="sd">    edge_order : {1, 2}, default=2</span>
<span class="sd">        Accuracy order of finite differences used in derivative computation.</span>
<span class="sd">    out : numpy.ndarray, optional</span>
<span class="sd">        Optional output buffer for storing the result. Must have shape equal to the broadcast of</span>
<span class="sd">        the grid (non-component) dimensions of `vector_field` and `Dterm_field`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray</span>
<span class="sd">        A scalar field representing the divergence, with shape equal to the broadcasted grid shape</span>
<span class="sd">        of `vector_field` and `Dterm_field` (excluding the final component axis).</span>


<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If `axes` length does not match the spatial rank of the input.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    In the most basic case, we only need to supply the D-field and the vector field.</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Build a field.</span>
<span class="sd">    &gt;&gt;&gt; x,y = np.linspace(-1,1,5),np.linspace(-1,1,5)</span>
<span class="sd">    &gt;&gt;&gt; X,Y = np.meshgrid(x,y,indexing=&#39;ij&#39;)</span>
<span class="sd">    &gt;&gt;&gt; V = np.stack([np.ones_like(X),Y],axis=-1)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Create cartesian Dfield.</span>
<span class="sd">    &gt;&gt;&gt; D = np.zeros_like(V)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Compute the divergence.</span>
<span class="sd">    &gt;&gt;&gt; DivV = dense_vector_divergence_contravariant(V,D,x,y)</span>
<span class="sd">    &gt;&gt;&gt; np.all(DivV == 1.0)</span>
<span class="sd">    True</span>

<span class="sd">    In some cases, the D term and the vector field might only be broadcastable. This</span>
<span class="sd">    is perfectly fine, but the fields must be broadcastable already! For example, this will</span>
<span class="sd">    fail:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Build a field.</span>
<span class="sd">    &gt;&gt;&gt; x,y = np.linspace(-1,1,6),np.linspace(-1,1,5)</span>
<span class="sd">    &gt;&gt;&gt; X,Y = np.meshgrid(x,y,indexing=&#39;ij&#39;)</span>
<span class="sd">    &gt;&gt;&gt; V = np.stack([np.ones_like(y),y],axis=-1)</span>
<span class="sd">    &gt;&gt;&gt; V.shape</span>
<span class="sd">    (5, 2)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Create cartesian Dfield.</span>
<span class="sd">    &gt;&gt;&gt; D = np.zeros(x.shape + (2,))</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Compute the divergence.</span>
<span class="sd">    &gt;&gt;&gt; DivV = dense_vector_divergence_contravariant(V,D,x,y) # doctest: +SKIP</span>
<span class="sd">    ValueError: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (5,) and arg 1 with shape (6,).</span>

<span class="sd">    This will succeed:</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Build a field.</span>
<span class="sd">    &gt;&gt;&gt; x,y = np.linspace(-1,1,6),np.linspace(-1,1,5)</span>
<span class="sd">    &gt;&gt;&gt; X,Y = np.meshgrid(x,y,indexing=&#39;ij&#39;)</span>
<span class="sd">    &gt;&gt;&gt; V = np.stack([np.ones_like(y),y],axis=-1)[None,:,:]</span>
<span class="sd">    &gt;&gt;&gt; V.shape</span>
<span class="sd">    (1, 5, 2)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Create cartesian Dfield.</span>
<span class="sd">    &gt;&gt;&gt; D = np.zeros(x.shape + (2,))[:,None,:]</span>
<span class="sd">    &gt;&gt;&gt; D.shape</span>
<span class="sd">    (6, 1, 2)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Compute the divergence.</span>
<span class="sd">    &gt;&gt;&gt; DivV = dense_vector_divergence_contravariant(V,D,y,derivative_axes=[1])</span>
<span class="sd">    &gt;&gt;&gt; np.all(DivV == 1.0)</span>
<span class="sd">    True</span>

<span class="sd">    The ``derivative_axes=[1]`` tells :func:`dense_vector_divergence_contravariant` not to</span>
<span class="sd">    compute a derivative over the `x` axis (its singleton).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Allocating the output array. This requires computing the broadcasted</span>
    <span class="c1"># shape if it is not pre-specified so that we don&#39;t try to assign to singletons.</span>
    <span class="n">broadcast_shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_shapes</span><span class="p">(</span>
        <span class="n">vector_field</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">Dterm_field</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">grid_dimension</span> <span class="o">=</span> <span class="n">vector_field</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">broadcast_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">vector_field</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>

    <span class="c1"># Set the field axes and the derivative axes.</span>
    <span class="k">if</span> <span class="n">field_axes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">field_axes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">grid_dimension</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">derivative_axes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">derivative_axes</span> <span class="o">=</span> <span class="n">field_axes</span>

    <span class="c1"># Correct varargs so that we can treat it as an iterable if a scalar is</span>
    <span class="c1"># provided.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">varargs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">varargs</span> <span class="o">*=</span> <span class="nb">len</span><span class="p">(</span><span class="n">field_axes</span><span class="p">)</span>

    <span class="c1"># Begin the computation of the divergence using the</span>
    <span class="c1"># two-term approach. We start by computing the contraction over</span>
    <span class="c1"># the Dterm and the vector field and placing it in out.</span>
    <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">Dterm_field</span> <span class="o">*</span> <span class="n">vector_field</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>

    <span class="c1"># We now need to complete the second term by computing</span>
    <span class="c1"># each of the derivatives and placing them into the buffer.</span>
    <span class="c1"># If they are pre-computed, then we can skip over this step.</span>
    <span class="k">if</span> <span class="n">derivative_field</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># We have precomputed derivatives. We need the broadcasting wrapper</span>
        <span class="c1"># because broadcasting doesn&#39;t work with inplace arithmetic.</span>
        <span class="n">out</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">derivative_field</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">broadcast_shape</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># We need to compute the derivatives. We have `derivative_axes` specifying</span>
        <span class="c1"># which axes we take derivatives of. For each, `field_axes` tells us which element</span>
        <span class="c1"># we want.</span>

        <span class="c1"># Iterate through each pairing and compute the derivative.</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">diff_index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">derivative_axes</span><span class="p">):</span>
            <span class="n">field_axis</span> <span class="o">=</span> <span class="n">field_axes</span><span class="p">[</span><span class="n">diff_index</span><span class="p">]</span>
            <span class="n">out</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
                    <span class="n">vector_field</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">field_axis</span><span class="p">],</span>
                    <span class="n">varargs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">axis</span><span class="o">=</span><span class="n">diff_index</span><span class="p">,</span>
                    <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">broadcast_shape</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">return</span> <span class="n">out</span></div>



<div class="viewcode-block" id="dense_vector_divergence_covariant_full">
<a class="viewcode-back" href="../../_as_gen/differential_geometry.dense_ops.dense_vector_divergence_covariant_full.html#differential_geometry.dense_ops.dense_vector_divergence_covariant_full">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">dense_vector_divergence_covariant_full</span><span class="p">(</span>
    <span class="n">vector_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">Dterm_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">inverse_metric_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
    <span class="n">field_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">derivative_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_order</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the divergence of a covariant vector field in a general coordinate system using</span>
<span class="sd">    a full inverse metric tensor.</span>

<span class="sd">    This function converts the covariant vector field to its contravariant form by contracting</span>
<span class="sd">    with the inverse metric, and then computes the divergence using:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \nabla_i V^i = D_i V^i + \partial_i V^i</span>

<span class="sd">    where:</span>

<span class="sd">    - :math:`V^i = g^{ij} V_j` is the contravariant form of the input covariant field.</span>
<span class="sd">    - :math:`D_i = (\partial_i \rho) / \rho` is the logarithmic derivative of the volume density.</span>
<span class="sd">    - :math:`\nabla_i V^i` is the full covariant divergence in curved space.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    vector_field : numpy.ndarray</span>
<span class="sd">        Contravariant vector field with shape ``(F_1, ..., F_M, ndim)``, where the final axis corresponds to coordinate</span>
<span class="sd">        directions. The first ``m`` axes are spatial grid axes. Must be broadcast-compatible with `Dterm_field`.</span>
<span class="sd">    Dterm_field : numpy.ndarray</span>
<span class="sd">        D-term array of shape ``(..., ndim)``, where the last axis matches the number of coordinate directions.</span>
<span class="sd">        Must broadcast with the spatial axes of `vector_field`.</span>
<span class="sd">    inverse_metric_field :  numpy.ndarray</span>
<span class="sd">        Inverse metric tensor with shape (..., N, N). This is used to raise the index of the covariant field.</span>
<span class="sd">    *varargs :</span>
<span class="sd">        Grid spacing for each axis. Follows the same format as :func:`numpy.gradient`, and can be:</span>

<span class="sd">        - A single scalar (applied to all spatial axes),</span>
<span class="sd">        - A list of scalars (one per axis),</span>
<span class="sd">        - A list of coordinate arrays (one per axis),</span>
<span class="sd">        - A mix of scalars and arrays (broadcast-compatible).</span>

<span class="sd">        If `derivative_axes` is provided, then `varargs` must match its shape. Otherwise, there must be ``M`` elements</span>
<span class="sd">        in `varargs`.</span>
<span class="sd">    field_axes : list of int, optional</span>
<span class="sd">        Maps each grid axis (0 to ``m-1``) to a corresponding component index in the vector field.</span>
<span class="sd">        Defaults to identity mapping ``[0, 1, ..., m-1]``.</span>
<span class="sd">    derivative_axes : list of int, optional</span>
<span class="sd">        Grid axes along which to compute partial derivatives. If not specified, all spatial axes</span>
<span class="sd">        listed in `field_axes` are used.</span>
<span class="sd">    edge_order : {1, 2}, default=2</span>
<span class="sd">        Accuracy order of finite differences used in derivative computation.</span>
<span class="sd">    out :  numpy.ndarray, optional</span>
<span class="sd">        Optional output buffer into which the result is placed. Specifying `out` can help to conserve</span>
<span class="sd">        memory.</span>

<span class="sd">        `out` should be specified so that it is the broadcast shape of `vector_field` and `Dterm_field` excluding</span>
<span class="sd">        the final (component) dimension of each. Thus, if `vector_field` is ``(A,B,1,3)`` and `Dterm_field` is ``(1,B,C,3)``,</span>
<span class="sd">        `out` should be ``(A,B,C)``.</span>
<span class="sd">    **kwargs :</span>
<span class="sd">        Additional keyword arguments passed to the metric contraction routine.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ~numpy.ndarray</span>
<span class="sd">        Divergence of the covariant vector field, with shape `vector_field.shape[:-1]`.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    dense_vector_divergence_contravariant : Performs divergence on contravariant fields.</span>
<span class="sd">    ~differential_geometry.dense_utils.dense_contract_with_metric : Raises the index of the vector field via contraction.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_contra_vec_field_</span> <span class="o">=</span> <span class="n">_dense_contract_index_with_metric</span><span class="p">(</span>
        <span class="n">vector_field</span><span class="p">,</span> <span class="n">inverse_metric_field</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">dense_vector_divergence_contravariant</span><span class="p">(</span>
        <span class="n">_contra_vec_field_</span><span class="p">,</span>
        <span class="n">Dterm_field</span><span class="p">,</span>
        <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
        <span class="n">derivative_axes</span><span class="o">=</span><span class="n">derivative_axes</span><span class="p">,</span>
        <span class="n">field_axes</span><span class="o">=</span><span class="n">field_axes</span><span class="p">,</span>
        <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
        <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="dense_vector_divergence_covariant_diag">
<a class="viewcode-back" href="../../_as_gen/differential_geometry.dense_ops.dense_vector_divergence_covariant_diag.html#differential_geometry.dense_ops.dense_vector_divergence_covariant_diag">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">dense_vector_divergence_covariant_diag</span><span class="p">(</span>
    <span class="n">vector_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">Dterm_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">inverse_metric_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
    <span class="n">field_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">derivative_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_order</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the divergence of a covariant vector field in a general curvilinear coordinate system</span>
<span class="sd">    using a **diagonal** inverse metric tensor.</span>

<span class="sd">    This function raises the index of the covariant field using a diagonal inverse metric,</span>
<span class="sd">    and then computes the divergence of the resulting contravariant vector field. The method</span>
<span class="sd">    implements:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \nabla_\mu V^\mu = D_\mu V^\mu + \partial_\mu V^\mu</span>

<span class="sd">    where:</span>

<span class="sd">    - :math:`V^\mu = g^{\mu\mu} V_\mu` is the contravariant vector field obtained by index raising,</span>
<span class="sd">    - :math:`D_\mu = \frac{\partial_\mu \rho}{\rho}` is the logarithmic derivative of the volume element,</span>
<span class="sd">    - The divergence is computed as the sum of the D-term contraction and the raw partial derivatives.</span>

<span class="sd">    This is a low-level routine and assumes input arrays are already correctly aligned and broadcast-compatible.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    vector_field : numpy.ndarray</span>
<span class="sd">        Covariant vector field of shape ``(F1, ..., Fm, ndim)``, where the final axis indexes vector components,</span>
<span class="sd">        and the leading ``m`` axes define the spatial grid dimensions. This field must be broadcast-compatible</span>
<span class="sd">        with `Dterm_field` and `inverse_metric_field`.</span>

<span class="sd">    Dterm_field : numpy.ndarray</span>
<span class="sd">        Log-volume term array of shape ``(..., ndim)``, where the last axis matches the number of coordinate directions.</span>
<span class="sd">        Must be broadcast-compatible with the spatial dimensions of `vector_field`.</span>

<span class="sd">    inverse_metric_field : numpy.ndarray</span>
<span class="sd">        Diagonal inverse metric tensor with shape ``(..., ndim)``, where the final dimension indexes the</span>
<span class="sd">        diagonal entries :math:`g^{\mu\mu}`. The leading dimensions must be broadcast-compatible with the</span>
<span class="sd">        spatial shape of `vector_field`.</span>

<span class="sd">    *varargs :</span>
<span class="sd">        Grid spacing for each axis. Accepts:</span>

<span class="sd">        - A single scalar (applied to all axes),</span>
<span class="sd">        - A list of scalars (one per axis),</span>
<span class="sd">        - A list of coordinate arrays,</span>
<span class="sd">        - A mix of scalars and arrays.</span>

<span class="sd">        If `derivative_axes` is specified, the number of elements in `varargs` must match its length.</span>
<span class="sd">        Otherwise, `varargs` must match the number of spatial dimensions in `vector_field`.</span>

<span class="sd">    field_axes : list of int, optional</span>
<span class="sd">        Indices mapping each spatial grid axis to a corresponding component in the final axis of `vector_field`.</span>
<span class="sd">        Defaults to ``[0, 1, ..., m-1]`` if not provided.</span>

<span class="sd">    derivative_axes : list of int, optional</span>
<span class="sd">        Subset of spatial axes over which to compute derivatives. This allows partial divergence over a subset of axes.</span>
<span class="sd">        Defaults to `field_axes` if not specified.</span>

<span class="sd">    edge_order : {1, 2}, default=2</span>
<span class="sd">        Accuracy order for finite difference gradients at the array boundaries.</span>

<span class="sd">    out : numpy.ndarray, optional</span>
<span class="sd">        Optional output buffer to store the result. Must have shape equal to the broadcasted grid shape</span>
<span class="sd">        of `vector_field` and `Dterm_field` (i.e., ``(F1, ..., Fm)``). If not provided, it is allocated internally.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray</span>
<span class="sd">        Scalar divergence of the covariant vector field after index raising, with shape equal to the broadcasted</span>
<span class="sd">        spatial shape of `vector_field` and `Dterm_field`.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This routine is equivalent to:</span>

<span class="sd">    .. code-block:: python</span>

<span class="sd">        V_contra = g^{mumu} * V_cov</span>
<span class="sd">        div = D_mu * V^mu + diff_mu V^mu</span>

<span class="sd">    but optimized for diagonal metrics to avoid unnecessary full tensor contractions.</span>

<span class="sd">    No validation is performed on input shapes—use higher-level wrappers for shape checking and metric inference.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    dense_vector_divergence_contravariant : Computes divergence from contravariant vector fields.</span>
<span class="sd">    dense_vector_divergence_covariant_full : Version supporting full inverse metric tensors.</span>
<span class="sd">    compute_divergence : High-level user-facing wrapper.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from pymetric.differential_geometry.dense_ops import dense_vector_divergence_covariant_diag</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Grid</span>
<span class="sd">    &gt;&gt;&gt; x = np.linspace(0.01, 1.0, 100)</span>
<span class="sd">    &gt;&gt;&gt; y = np.linspace(0.1, np.pi - 0.1, 100)</span>
<span class="sd">    &gt;&gt;&gt; X, Y = np.meshgrid(x, y, indexing=&#39;ij&#39;)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Covariant field: V_r = x, V_theta = sin(theta)</span>
<span class="sd">    &gt;&gt;&gt; V = np.stack([X, np.sin(Y)], axis=-1)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # D-terms (e.g., spherical coords): D_r = 2/x, D_theta = 1/tan(theta)</span>
<span class="sd">    &gt;&gt;&gt; Dr = 2 / X</span>
<span class="sd">    &gt;&gt;&gt; Dtheta = 1 / np.tan(Y)</span>
<span class="sd">    &gt;&gt;&gt; D = np.stack([Dr, Dtheta], axis=-1)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Diagonal inverse metric: g^rr = 1, g^thetatheta = 1/x^2</span>
<span class="sd">    &gt;&gt;&gt; IM_diag = np.stack([np.ones_like(X), 1 / X**2], axis=-1)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Compute divergence</span>
<span class="sd">    &gt;&gt;&gt; div = dense_vector_divergence_covariant_diag(V, D, IM_diag, x, y)</span>
<span class="sd">    &gt;&gt;&gt; div.shape</span>
<span class="sd">    (100, 100)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_contra_vec_field_</span> <span class="o">=</span> <span class="n">_dense_contract_index_with_diagonal_metric</span><span class="p">(</span>
        <span class="n">vector_field</span><span class="p">,</span> <span class="n">inverse_metric_field</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">dense_vector_divergence_contravariant</span><span class="p">(</span>
        <span class="n">_contra_vec_field_</span><span class="p">,</span>
        <span class="n">Dterm_field</span><span class="p">,</span>
        <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
        <span class="n">derivative_axes</span><span class="o">=</span><span class="n">derivative_axes</span><span class="p">,</span>
        <span class="n">field_axes</span><span class="o">=</span><span class="n">field_axes</span><span class="p">,</span>
        <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
        <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="dense_vector_divergence">
<a class="viewcode-back" href="../../_as_gen/differential_geometry.dense_ops.dense_vector_divergence.html#differential_geometry.dense_ops.dense_vector_divergence">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">dense_vector_divergence</span><span class="p">(</span>
    <span class="n">vector_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">Dterm_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
    <span class="n">basis</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;contravariant&quot;</span><span class="p">,</span> <span class="s2">&quot;covariant&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;contravariant&quot;</span><span class="p">,</span>
    <span class="n">inverse_metric_field</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">derivative_field</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">field_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">derivative_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_order</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the divergence of a vector field in a general coordinate system.</span>

<span class="sd">    This high-level routine supports both **contravariant** and **covariant** vector fields. For covariant fields,</span>
<span class="sd">    the divergence is computed by first raising the index using the inverse metric tensor, then applying the</span>
<span class="sd">    conservative divergence formula:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \nabla_\mu V^\mu = D_\mu V^\mu + \partial_\mu V^\mu</span>

<span class="sd">    where:</span>

<span class="sd">    - :math:`V^\mu` is a contravariant vector field,</span>
<span class="sd">    - :math:`D_\mu = (\partial_\mu \rho)/\rho` is the logarithmic derivative of the volume element,</span>
<span class="sd">    - The divergence is evaluated as a sum of the D-term contraction and raw partial derivatives.</span>

<span class="sd">    The metric can be either full or diagonal, and this function automatically dispatches</span>
<span class="sd">    to the appropriate backend implementation.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    vector_field : numpy.ndarray</span>
<span class="sd">        Input vector field of shape ``(F1, ..., Fm, ndim)``, where the final axis indexes the vector components</span>
<span class="sd">        and the first ``m`` axes represent spatial grid dimensions.</span>

<span class="sd">        If `basis=&quot;covariant&quot;`, this is treated as a covariant field whose index will be raised.</span>
<span class="sd">        If `basis=&quot;contravariant&quot;`, the field is used directly.</span>

<span class="sd">    Dterm_field : numpy.ndarray</span>
<span class="sd">        Log-volume term array of shape ``(..., ndim)``, where the final axis matches the number of coordinate axes.</span>
<span class="sd">        Must be broadcast-compatible with the spatial dimensions of `vector_field`.</span>

<span class="sd">    *varargs :</span>
<span class="sd">        Grid spacing for each spatial axis. Accepts:</span>

<span class="sd">        - A single scalar (applied to all axes),</span>
<span class="sd">        - A list of scalars (one per axis),</span>
<span class="sd">        - A list of coordinate arrays (one per axis),</span>
<span class="sd">        - A mix of scalars and arrays (broadcast-compatible).</span>

<span class="sd">        If `derivative_axes` is provided, the number of elements in `varargs` must match its length.</span>
<span class="sd">        Otherwise, `varargs` must match the number of spatial dimensions in `vector_field`.</span>

<span class="sd">    basis : {&#39;contravariant&#39;, &#39;covariant&#39;}, optional</span>
<span class="sd">        Specifies the form of the input vector field:</span>

<span class="sd">        - ``&#39;contravariant&#39;`` (default): treat the input as a contravariant field.</span>
<span class="sd">        - ``&#39;covariant&#39;``: raise the index using the inverse metric before computing divergence.</span>

<span class="sd">    inverse_metric_field : numpy.ndarray, optional</span>
<span class="sd">        Inverse metric tensor. Required if `basis=&#39;covariant&#39;`.</span>

<span class="sd">        Accepts:</span>

<span class="sd">        - Shape ``(..., ndim)`` for diagonal metric (:math:`g^{\mu\mu}`),</span>
<span class="sd">        - Shape ``(..., ndim, ndim)`` for full metric (:math:`g^{\mu\nu}`).</span>

<span class="sd">        Must be broadcast-compatible with the spatial shape of `vector_field`.</span>

<span class="sd">    derivative_field : numpy.ndarray, optional</span>
<span class="sd">        Optional precomputed partial derivatives of the vector field components.</span>
<span class="sd">        If provided, must have shape ``(..., k)``, where `k` is the number of derivatives being taken</span>
<span class="sd">        (i.e., length of `derivative_axes`).</span>

<span class="sd">    field_axes : list of int, optional</span>
<span class="sd">        Maps each spatial axis to the corresponding component index in `vector_field`.</span>
<span class="sd">        Defaults to ``[0, 1, ..., m-1]`` if not specified.</span>

<span class="sd">    derivative_axes : list of int, optional</span>
<span class="sd">        Axes over which to compute partial derivatives. Defaults to `field_axes` if not provided.</span>

<span class="sd">    out : numpy.ndarray, optional</span>
<span class="sd">        Output buffer for storing the divergence result. Must have shape equal to the broadcasted</span>
<span class="sd">        grid shape of `vector_field` and `Dterm_field` (excluding the final axis). If not provided,</span>
<span class="sd">        the buffer is allocated automatically.</span>

<span class="sd">    edge_order : {1, 2}, default=2</span>
<span class="sd">        Order of accuracy for finite differencing used by `numpy.gradient`.</span>

<span class="sd">    **kwargs :</span>
<span class="sd">        Additional keyword arguments forwarded to internal contraction routines.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray</span>
<span class="sd">        Scalar field representing the divergence of the input vector field.</span>
<span class="sd">        Shape is the broadcasted grid shape of `vector_field` and `Dterm_field`.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If required arguments are missing, incompatible with the basis, or have shape mismatches.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    dense_gradient : Computes the gradient of a tensor field.</span>
<span class="sd">    dense_vector_divergence_contravariant : Low-level divergence for contravariant fields.</span>
<span class="sd">    dense_vector_divergence_covariant_full : Divergence for covariant fields with full metrics.</span>
<span class="sd">    dense_vector_divergence_covariant_diag : Divergence for covariant fields with diagonal metrics.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    Compute the divergence of a vector field in 2D **spherical coordinates** :math:`(r, \theta)`:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \vec{V}(r, \theta) =</span>
<span class="sd">        \begin{bmatrix}</span>
<span class="sd">            r \</span>
<span class="sd">            \cos(k\theta)</span>
<span class="sd">        \end{bmatrix}</span>

<span class="sd">    with known volume density:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \rho(r, \theta) = r^2 \sin(\theta)</span>

<span class="sd">    which gives:</span>

<span class="sd">    .. math::</span>

<span class="sd">        D_r = \frac{2}{r}, \quad D_\theta = \frac{1}{\tan(\theta)},</span>
<span class="sd">        \quad g^{rr} = 1, \quad g^{\theta\theta} = \frac{1}{r^2}</span>

<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">    &gt;&gt;&gt; from pymetric.differential_geometry.dense_ops import compute_divergence</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Create coordinate grid</span>
<span class="sd">    &gt;&gt;&gt; r = np.linspace(0.01, 1.0, 100)</span>
<span class="sd">    &gt;&gt;&gt; theta = np.linspace(0.1, np.pi - 0.1, 100)  # avoid singularities</span>
<span class="sd">    &gt;&gt;&gt; R, THETA = np.meshgrid(r, theta, indexing=&#39;ij&#39;)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Define vector field: V^r = r, V^theta = cos(theta)</span>
<span class="sd">    &gt;&gt;&gt; Vr = R</span>
<span class="sd">    &gt;&gt;&gt; Vtheta = np.cos(THETA)</span>
<span class="sd">    &gt;&gt;&gt; vector = np.stack([Vr, Vtheta], axis=-1)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # D-terms</span>
<span class="sd">    &gt;&gt;&gt; D_r = 2 / R</span>
<span class="sd">    &gt;&gt;&gt; D_theta = 1 / np.tan(THETA)</span>
<span class="sd">    &gt;&gt;&gt; Dterm = np.stack([D_r, D_theta], axis=-1)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Inverse metric (diagonal)</span>
<span class="sd">    &gt;&gt;&gt; g_inv = np.stack([np.ones_like(R), 1 / R**2], axis=-1)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Compute divergence (contravariant)</span>
<span class="sd">    &gt;&gt;&gt; div = compute_divergence(vector, Dterm, r, theta, inverse_metric_field=g_inv, basis=&quot;contravariant&quot;)</span>
<span class="sd">    &gt;&gt;&gt;</span>
<span class="sd">    &gt;&gt;&gt; # Visualize</span>
<span class="sd">    &gt;&gt;&gt; _ = plt.imshow(div.T, extent=[0.01, 1.0, 0.1, np.pi-0.1], origin=&#39;lower&#39;, aspect=&#39;auto&#39;, cmap=&#39;RdBu&#39;)</span>
<span class="sd">    &gt;&gt;&gt; _ = plt.xlabel(&quot;r&quot;)</span>
<span class="sd">    &gt;&gt;&gt; _ = plt.ylabel(r&quot;$\theta$&quot;)</span>
<span class="sd">    &gt;&gt;&gt; _ = plt.title(r&quot;Divergence of $V = [r, \cos(\theta)]$ in Spherical Coordinates&quot;)</span>
<span class="sd">    &gt;&gt;&gt; _ = plt.colorbar(label=&quot;Divergence&quot;)</span>
<span class="sd">    &gt;&gt;&gt; _ = plt.tight_layout()</span>
<span class="sd">    &gt;&gt;&gt; _ = plt.show()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">basis</span> <span class="o">==</span> <span class="s2">&quot;contravariant&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dense_vector_divergence_contravariant</span><span class="p">(</span>
            <span class="n">vector_field</span><span class="p">,</span>
            <span class="n">Dterm_field</span><span class="p">,</span>
            <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
            <span class="n">derivative_field</span><span class="o">=</span><span class="n">derivative_field</span><span class="p">,</span>
            <span class="n">field_axes</span><span class="o">=</span><span class="n">field_axes</span><span class="p">,</span>
            <span class="n">derivative_axes</span><span class="o">=</span><span class="n">derivative_axes</span><span class="p">,</span>
            <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
            <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">basis</span> <span class="o">==</span> <span class="s2">&quot;covariant&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">inverse_metric_field</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;`inverse_metric_field` must be provided for covariant divergence.&quot;</span>
            <span class="p">)</span>

        <span class="n">spatial_shape</span> <span class="o">=</span> <span class="n">vector_field</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">metric_type</span> <span class="o">=</span> <span class="n">infer_metric_type</span><span class="p">(</span><span class="n">inverse_metric_field</span><span class="p">,</span> <span class="n">spatial_shape</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">metric_type</span> <span class="o">==</span> <span class="s2">&quot;full&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">dense_vector_divergence_covariant_full</span><span class="p">(</span>
                <span class="n">vector_field</span><span class="p">,</span>
                <span class="n">Dterm_field</span><span class="p">,</span>
                <span class="n">inverse_metric_field</span><span class="p">,</span>
                <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
                <span class="n">field_axes</span><span class="o">=</span><span class="n">field_axes</span><span class="p">,</span>
                <span class="n">derivative_axes</span><span class="o">=</span><span class="n">derivative_axes</span><span class="p">,</span>
                <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
                <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">metric_type</span> <span class="o">==</span> <span class="s2">&quot;diagonal&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">dense_vector_divergence_covariant_diag</span><span class="p">(</span>
                <span class="n">vector_field</span><span class="p">,</span>
                <span class="n">Dterm_field</span><span class="p">,</span>
                <span class="n">inverse_metric_field</span><span class="p">,</span>
                <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
                <span class="n">field_axes</span><span class="o">=</span><span class="n">field_axes</span><span class="p">,</span>
                <span class="n">derivative_axes</span><span class="o">=</span><span class="n">derivative_axes</span><span class="p">,</span>
                <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
                <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unrecognized metric type: </span><span class="si">{</span><span class="n">metric_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;`basis` must be &#39;contravariant&#39; or &#39;covariant&#39;, not &#39;</span><span class="si">{</span><span class="n">basis</span><span class="si">}</span><span class="s2">&#39;.&quot;</span>
        <span class="p">)</span></div>



<span class="c1"># =================================== #</span>
<span class="c1"># Laplacian Methods                   #</span>
<span class="c1"># =================================== #</span>
<span class="c1"># These methods are used to compute the Laplacian</span>
<span class="c1"># over some set of relevant tensor classes.</span>
<div class="viewcode-block" id="dense_scalar_laplacian_diag">
<a class="viewcode-back" href="../../_as_gen/differential_geometry.dense_ops.dense_scalar_laplacian_diag.html#differential_geometry.dense_ops.dense_scalar_laplacian_diag">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">dense_scalar_laplacian_diag</span><span class="p">(</span>
    <span class="n">tensor_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">Lterm_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">inverse_metric_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">ndim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
    <span class="n">field_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">derivative_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">first_derivative_field</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">second_derivative_field</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_order</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="o">**</span><span class="n">_</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the element-wise Laplacian of a densely represented tensor field in an orthogonal coordinate system.</span>

<span class="sd">    This method computes the Laplace-Beltrami operator for a for :math:`T`:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \Delta T = F^\mu \, \partial_\mu T + g^{\mu\mu} \, \partial^2_\mu T,</span>

<span class="sd">    where:</span>

<span class="sd">    - :math:`F^\mu = \frac{1}{\sqrt{|g|}} \, \partial_\mu \sqrt{|g|}` is the log-derivative of the volume element.</span>
<span class="sd">    - :math:`g^{\mu\mu}` is **symmetric** the inverse metric tensor.</span>
<span class="sd">    - The first term represents the contraction of the F-term and the gradient.</span>
<span class="sd">    - The second term is the contraction of the inverse metric with the Hessian (second derivatives).</span>

<span class="sd">    .. note::</span>

<span class="sd">        This operation is an **element-wise** operation!</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor_field : numpy.ndarray</span>
<span class="sd">        Tensor field of shape ``(F_1, ..., F_m, ndim, ...)``, where the last `rank` axes</span>
<span class="sd">        are the tensor index dimensions.</span>

<span class="sd">        .. hint::</span>

<span class="sd">            Because this function is a low-level callable, it does not enforce the density of</span>
<span class="sd">            the elements in the trailing dimensions of the field. This can be used in some cases where</span>
<span class="sd">            the field is not **technically** a tensor field.</span>
<span class="sd">    Lterm_field : numpy.ndarray</span>
<span class="sd">        The F-term field of shape ``(..., ndim)``, where the first ``m`` dimensions are</span>
<span class="sd">        broadcast compatible with those of ``tensor_field`` and ``inverse_metric_field``.</span>
<span class="sd">    inverse_metric_field : numpy.ndarray</span>
<span class="sd">        The inverse metric field of shape ``(..., ndim)``, where the first ``m`` dimensions are</span>
<span class="sd">        broadcast compatible with those of ``tensor_field`` and ``Fterm_field``.</span>
<span class="sd">    rank : int</span>
<span class="sd">        Number of trailing axes that represent tensor indices (i.e., tensor rank). The `rank` determines</span>
<span class="sd">        the number of identified coordinate axes and therefore determines the shape of the returned array.</span>
<span class="sd">    ndim: int</span>
<span class="sd">        The number of total dimensions in the relevant coordinate system. This determines the maximum allowed value</span>
<span class="sd">        for ``m`` and the number of elements in the trailing dimension of the output.</span>
<span class="sd">    *varargs :</span>
<span class="sd">        Grid spacing for each spatial axis. Accepts:</span>

<span class="sd">        - A single scalar (applied to all axes),</span>
<span class="sd">        - A list of scalars (one per axis),</span>
<span class="sd">        - A list of coordinate arrays (one per axis),</span>
<span class="sd">        - A mix of scalars and arrays (broadcast-compatible).</span>

<span class="sd">        If `derivative_axes` is provided, the number of elements in `varargs` must match its length.</span>
<span class="sd">        Otherwise, `varargs` must match the number of spatial dimensions in `tensor_field` (``m``).</span>
<span class="sd">    field_axes : list of int, optional</span>
<span class="sd">        Mapping between each spatial dimension of `tensor_field` and the corresponding coordinate axis</span>
<span class="sd">        it represents (and therefore the component it represents). `field_axes` should be a length ``m``</span>
<span class="sd">        sequence of integers between ``0`` and ``ndim-1``. If not specified, then `field_axes` is simply</span>
<span class="sd">        ``0, 1, ..., m-1``.</span>

<span class="sd">        Specifying `field_axes` is critical when working with fields which are incomplete over their</span>
<span class="sd">        spatial domain (missing axes) as `field_axes` determines how contraction occurs with derivative</span>
<span class="sd">        terms.</span>
<span class="sd">    derivative_axes : list of int, optional</span>
<span class="sd">        The axes of the `tensor_field` to perform derivatives over. By default, all ``m`` axes are</span>
<span class="sd">        used when computing derivatives.</span>

<span class="sd">        `derivative_axes` should be used when certain axes of `tensor_field` are constant and should</span>
<span class="sd">        be excluded from numerical differentiation. It can also be used when `tensor_field` has been</span>
<span class="sd">        broadcast to a new set of axes (and therefore has singleton axes) on which differentiation</span>
<span class="sd">        would fail.</span>
<span class="sd">    first_derivative_field :  numpy.ndarray, optional</span>
<span class="sd">        Precomputed first derivatives of the `tensor_field` with shape ``tensor_field.shape + (q,)``, where</span>
<span class="sd">        ``q`` is the number of axes in `derivative_axes` or (if the former is not provided), the number</span>
<span class="sd">        of spatial dimensions in `tensor_field` (``m``).</span>

<span class="sd">        Specifying `first_derivative_field` can be used to avoid having to compute the</span>
<span class="sd">        relevant derivatives numerically, which can improve efficiency and accuracy.</span>
<span class="sd">    second_derivative_field :  numpy.ndarray, optional</span>
<span class="sd">        Precomputed second derivatives of the `tensor_field` with shape ``tensor_field.shape + (q,q)``, where</span>
<span class="sd">        ``q`` is the number of axes in `derivative_axes` or (if the former is not provided), the number</span>
<span class="sd">        of spatial dimensions in `tensor_field` (``m``).</span>

<span class="sd">        Specifying `first_derivative_field` can be used to avoid having to compute the</span>
<span class="sd">        relevant derivatives numerically, which can improve efficiency and accuracy.</span>
<span class="sd">    edge_order : {1, 2}, optional</span>
<span class="sd">        Order of accuracy for boundary differences. Default is 2.</span>
<span class="sd">    out: numpy.ndarray, optional</span>
<span class="sd">        An output buffer into which the result should be written. This should be an ``(..., ndim, ...)`` array</span>
<span class="sd">        where the leading indices are the broadcasted shape of the spatial components of the `tensor_field`, `Fterm_field`,</span>
<span class="sd">        and the `inverse_metric_field`. The trailing indices must match the non-spatial shape of the `tensor_field`.</span>
<span class="sd">        If `out` is not specified, then a new buffer will be created with the correct shape.</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ~numpy.ndarray</span>
<span class="sd">        Laplacian of `tensor_field` with shape ``tensor_field.shape``.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function assumes a full inverse metric (not diagonal) and uses upper-triangular evaluation of</span>
<span class="sd">    second derivatives to reduce computation using symmetry.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    dense_gradient</span>
<span class="sd">    dense_scalar_laplacian_full</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    This example demonstrates computing the Laplace-Beltrami operator for a scalar field</span>
<span class="sd">    in 2D **spherical coordinates** :math:`(r, \theta)`.</span>

<span class="sd">    We define the scalar field:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \phi(r, \theta) = r^2 \cos(\theta)</span>

<span class="sd">    The Laplace-Beltrami operator in spherical coordinates is given by:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \Delta \phi =</span>
<span class="sd">            \frac{1}{r^2} \frac{\partial}{\partial r} \left( r^2 \frac{\partial \phi}{\partial r} \right)</span>
<span class="sd">            + \frac{1}{r^2 \sin\theta} \frac{\partial}{\partial \theta} \left( \sin\theta \frac{\partial \phi}{\partial \theta} \right)</span>

<span class="sd">    which expands to:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \Delta \phi =</span>
<span class="sd">            F^\mu \, \partial_\mu \phi + g^{\mu\nu} \, \partial_\mu \partial_\nu \phi</span>

<span class="sd">    where:</span>

<span class="sd">    - :math:`F^r = \frac{2}{r}`, the derivative of :math:`\log r^2`</span>
<span class="sd">    - :math:`F^\theta = \cot(\theta)`, the derivative of :math:`\log \sin(\theta)`</span>
<span class="sd">    - :math:`g^{rr} = 1`, :math:`g^{\theta\theta} = \frac{1}{r^2}` are the components of the inverse metric</span>

<span class="sd">    .. plot::</span>
<span class="sd">        :include-source: True</span>

<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">        &gt;&gt;&gt; from pymetric.differential_geometry.dense_ops import dense_scalar_laplacian_diag</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # --- Grid in spherical coordinates --- #</span>
<span class="sd">        &gt;&gt;&gt; r = np.linspace(0.01, 1.0, 100)</span>
<span class="sd">        &gt;&gt;&gt; theta = np.linspace(0.1, np.pi - 0.1, 100)  # avoid tan(theta)=0</span>
<span class="sd">        &gt;&gt;&gt; R, THETA = np.meshgrid(r, theta, indexing=&#39;ij&#39;)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # --- Scalar field phi(r, theta) = r^2 * cos(theta) --- #</span>
<span class="sd">        &gt;&gt;&gt; phi = R**2 * np.cos(THETA)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # --- F-term: [2/r, cot(theta)] --- #</span>
<span class="sd">        &gt;&gt;&gt; Fterm = np.zeros(R.shape + (2,))</span>
<span class="sd">        &gt;&gt;&gt; Fterm[:,:,0] = 2 / R</span>
<span class="sd">        &gt;&gt;&gt; Fterm[:,:,1] = 1 / (R**2 * np.tan(THETA))</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # --- Inverse metric --- #</span>
<span class="sd">        &gt;&gt;&gt; IM = np.zeros(R.shape + (2,))</span>
<span class="sd">        &gt;&gt;&gt; IM[..., 0] = 1</span>
<span class="sd">        &gt;&gt;&gt; IM[..., 1] = 1 / R**2</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # --- Compute Laplacian --- #</span>
<span class="sd">        &gt;&gt;&gt; lap = dense_scalar_laplacian_diag(phi, Fterm, IM, 0,2,r,theta)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # --- Plot --- #</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.imshow(lap.T, origin=&#39;lower&#39;, extent=[0.01, 1.0, 0.1, np.pi - 0.1], aspect=&#39;auto&#39;, cmap=&#39;viridis&#39;)</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.colorbar(label=r&quot;Laplacian $\Delta \phi$&quot;)</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.title(r&quot;Laplacian of $\phi(r, \theta) = r^2 \cos(\theta)$&quot;)</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.xlabel(&quot;r&quot;)</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.ylabel(r&quot;$\theta$&quot;)</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.tight_layout()</span>
<span class="sd">        &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># --- Relevant Constants --- #</span>
    <span class="c1"># Extract the shapes from the arrays so that we</span>
    <span class="c1"># can work with them.</span>
    <span class="n">field_ndim</span><span class="p">,</span> <span class="n">fterm_ndim</span> <span class="o">=</span> <span class="n">tensor_field</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="n">Lterm_field</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">tf_shape</span><span class="p">,</span> <span class="n">imf_shape</span><span class="p">,</span> <span class="n">ftf_shape</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tensor_field</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">inverse_metric_field</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">Lterm_field</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_buffer_shape_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_shapes</span><span class="p">(</span>
        <span class="n">tf_shape</span><span class="p">[:</span> <span class="n">field_ndim</span> <span class="o">-</span> <span class="n">rank</span><span class="p">],</span>  <span class="c1"># spatial component of TF</span>
        <span class="n">imf_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>  <span class="c1"># spatial component of IMF</span>
        <span class="n">ftf_shape</span><span class="p">[:</span> <span class="n">fterm_ndim</span> <span class="o">-</span> <span class="p">(</span><span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)],</span>  <span class="c1"># spatial component of the Fterm field.</span>
    <span class="p">)</span>

    <span class="c1"># Propagate the varargs out in case they are</span>
    <span class="c1"># scalar.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">varargs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">varargs</span> <span class="o">*=</span> <span class="n">field_ndim</span>

    <span class="c1"># Fill in missing information.</span>
    <span class="k">if</span> <span class="n">field_axes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">field_axes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">field_ndim</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">derivative_axes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">derivative_axes</span> <span class="o">=</span> <span class="n">field_axes</span>

    <span class="n">derivative_axes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">derivative_axes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">field_axes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">field_axes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># --- Generate the output buffer --- #</span>
    <span class="c1"># the output buffer needs to be broadcast compatible</span>
    <span class="c1"># with the various fields.</span>
    <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">_buffer_shape_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor_field</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>

    <span class="c1"># --- Compute Term 1 --- #</span>
    <span class="c1"># The first term is the contraction between the F-terms and the</span>
    <span class="c1"># first derivatives.</span>
    <span class="k">if</span> <span class="n">first_derivative_field</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># The first derivatives needs to be computed. We either want to</span>
        <span class="c1"># do this and allocate for it (if we need them later) or just</span>
        <span class="c1"># pass through and dump (if we don&#39;t need them later).</span>
        <span class="k">if</span> <span class="n">second_derivative_field</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># We will need to allocate the second derivatives so we</span>
            <span class="c1"># need to hold onto the 1st derivatives.</span>
            <span class="n">first_derivative_field</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="n">tf_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">ndim</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span>
            <span class="p">)</span>
            <span class="n">dense_gradient_covariant</span><span class="p">(</span>
                <span class="n">tensor_field</span><span class="p">,</span>
                <span class="n">rank</span><span class="p">,</span>
                <span class="n">ndim</span><span class="p">,</span>
                <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
                <span class="n">field_axes</span><span class="o">=</span><span class="n">derivative_axes</span><span class="p">,</span>
                <span class="n">output_indices</span><span class="o">=</span><span class="n">field_axes</span><span class="p">[</span><span class="n">derivative_axes</span><span class="p">],</span>
                <span class="n">out</span><span class="o">=</span><span class="n">first_derivative_field</span><span class="p">,</span>
                <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Dump the contraction result to `out`. We have all `ndim` elements in `Fterm`.</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
                    <span class="n">Lterm_field</span> <span class="o">*</span> <span class="n">first_derivative_field</span><span class="p">,</span> <span class="n">_buffer_shape_</span> <span class="o">+</span> <span class="p">(</span><span class="n">ndim</span><span class="p">,)</span>
                <span class="p">),</span>
                <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># We don&#39;t need to store the derivatives in memory because we only use them</span>
            <span class="c1"># once so we can just go through and compute the derivatives.</span>
            <span class="k">for</span> <span class="n">diff_index</span><span class="p">,</span> <span class="n">diff_axis</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">derivative_axes</span><span class="p">):</span>
                <span class="n">comp_index</span> <span class="o">=</span> <span class="n">field_axes</span><span class="p">[</span><span class="n">diff_index</span><span class="p">]</span>
                <span class="n">out</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
                    <span class="n">Lterm_field</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">comp_index</span><span class="p">]</span>
                    <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
                        <span class="n">tensor_field</span><span class="p">,</span>
                        <span class="n">varargs</span><span class="p">[</span><span class="n">diff_index</span><span class="p">],</span>
                        <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
                        <span class="n">axis</span><span class="o">=</span><span class="n">diff_axis</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">_buffer_shape_</span><span class="p">,</span>
                <span class="p">)</span>

    <span class="c1"># --- Compute Term 2 --- #</span>
    <span class="c1"># At this stage, we take advantage of Schwarz&#39; Theorem to cut down on the number</span>
    <span class="c1"># of derivatives we actually have to compute. We just use the upper triangular segment</span>
    <span class="c1"># of the second derivative tensor.</span>
    <span class="k">if</span> <span class="n">second_derivative_field</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># We are already given the second derivative field, so we just need to ensure</span>
        <span class="c1"># that the summation occurs properly.</span>
        <span class="n">out</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">second_derivative_field</span> <span class="o">*</span> <span class="n">inverse_metric_field</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)),</span>
            <span class="n">_buffer_shape_</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">diff_index</span><span class="p">,</span> <span class="n">diff_axis</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">derivative_axes</span><span class="p">):</span>
            <span class="n">comp_index</span> <span class="o">=</span> <span class="n">field_axes</span><span class="p">[</span><span class="n">diff_index</span><span class="p">]</span>
            <span class="n">out</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
                <span class="n">inverse_metric_field</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">comp_index</span><span class="p">]</span>
                <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
                    <span class="n">first_derivative_field</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">comp_index</span><span class="p">],</span>
                    <span class="n">varargs</span><span class="p">[</span><span class="n">diff_index</span><span class="p">],</span>
                    <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
                    <span class="n">axis</span><span class="o">=</span><span class="n">diff_axis</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">_buffer_shape_</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">return</span> <span class="n">out</span></div>



<div class="viewcode-block" id="dense_scalar_laplacian_full">
<a class="viewcode-back" href="../../_as_gen/differential_geometry.dense_ops.dense_scalar_laplacian_full.html#differential_geometry.dense_ops.dense_scalar_laplacian_full">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">dense_scalar_laplacian_full</span><span class="p">(</span>
    <span class="n">tensor_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">Lterm_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">inverse_metric_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">ndim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
    <span class="n">field_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">derivative_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">first_derivative_field</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">second_derivative_field</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_order</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="o">**</span><span class="n">_</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the element-wise Laplacian of a densely represented tensor field.</span>

<span class="sd">    This method computes the Laplace-Beltrami operator for a for :math:`T`:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \Delta T = F^\mu \, \partial_\mu T + g^{\mu\nu} \, \partial_\mu \partial_\nu T,</span>

<span class="sd">    where:</span>

<span class="sd">    - :math:`F^\mu = \frac{1}{\sqrt{|g|}} \, \partial_\mu \sqrt{|g|}` is the log-derivative of the volume element.</span>
<span class="sd">    - :math:`g^{\mu\nu}` is the inverse metric tensor.</span>
<span class="sd">    - The first term represents the contraction of the F-term and the gradient.</span>
<span class="sd">    - The second term is the contraction of the inverse metric with the Hessian (second derivatives).</span>

<span class="sd">    .. note::</span>

<span class="sd">        This operation is an **element-wise** operation!</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor_field : numpy.ndarray</span>
<span class="sd">        Tensor field of shape ``(F_1, ..., F_m, ndim, ...)``, where the last `rank` axes</span>
<span class="sd">        are the tensor index dimensions.</span>

<span class="sd">        .. hint::</span>

<span class="sd">            Because this function is a low-level callable, it does not enforce the density of</span>
<span class="sd">            the elements in the trailing dimensions of the field. This can be used in some cases where</span>
<span class="sd">            the field is not **technically** a tensor field.</span>
<span class="sd">    Lterm_field : numpy.ndarray</span>
<span class="sd">        The F-term field of shape ``(..., ndim)``, where the first ``m`` dimensions are</span>
<span class="sd">        broadcast compatible with those of ``tensor_field`` and ``inverse_metric_field``.</span>
<span class="sd">    inverse_metric_field : numpy.ndarray</span>
<span class="sd">        The inverse metric field of shape ``(..., ndim, ndim)``, where the first ``m`` dimensions are</span>
<span class="sd">        broadcast compatible with those of ``tensor_field`` and ``Fterm_field``.</span>
<span class="sd">    rank : int</span>
<span class="sd">        Number of trailing axes that represent tensor indices (i.e., tensor rank). The `rank` determines</span>
<span class="sd">        the number of identified coordinate axes and therefore determines the shape of the returned array.</span>
<span class="sd">    ndim: int</span>
<span class="sd">        The number of total dimensions in the relevant coordinate system. This determines the maximum allowed value</span>
<span class="sd">        for ``m`` and the number of elements in the trailing dimension of the output.</span>
<span class="sd">    *varargs :</span>
<span class="sd">        Grid spacing for each spatial axis. Accepts:</span>

<span class="sd">        - A single scalar (applied to all axes),</span>
<span class="sd">        - A list of scalars (one per axis),</span>
<span class="sd">        - A list of coordinate arrays (one per axis),</span>
<span class="sd">        - A mix of scalars and arrays (broadcast-compatible).</span>

<span class="sd">        If `derivative_axes` is provided, the number of elements in `varargs` must match its length.</span>
<span class="sd">        Otherwise, `varargs` must match the number of spatial dimensions in `tensor_field` (``m``).</span>
<span class="sd">    field_axes : list of int, optional</span>
<span class="sd">        Mapping between each spatial dimension of `tensor_field` and the corresponding coordinate axis</span>
<span class="sd">        it represents (and therefore the component it represents). `field_axes` should be a length ``m``</span>
<span class="sd">        sequence of integers between ``0`` and ``ndim-1``. If not specified, then `field_axes` is simply</span>
<span class="sd">        ``0, 1, ..., m-1``.</span>

<span class="sd">        Specifying `field_axes` is critical when working with fields which are incomplete over their</span>
<span class="sd">        spatial domain (missing axes) as `field_axes` determines how contraction occurs with derivative</span>
<span class="sd">        terms.</span>
<span class="sd">    derivative_axes : list of int, optional</span>
<span class="sd">        The axes of the `tensor_field` to perform derivatives over. By default, all ``m`` axes are</span>
<span class="sd">        used when computing derivatives.</span>

<span class="sd">        `derivative_axes` should be used when certain axes of `tensor_field` are constant and should</span>
<span class="sd">        be excluded from numerical differentiation. It can also be used when `tensor_field` has been</span>
<span class="sd">        broadcast to a new set of axes (and therefore has singleton axes) on which differentiation</span>
<span class="sd">        would fail.</span>
<span class="sd">    first_derivative_field :  numpy.ndarray, optional</span>
<span class="sd">        Precomputed first derivatives of the `tensor_field` with shape ``tensor_field.shape + (q,)``, where</span>
<span class="sd">        ``q`` is the number of axes in `derivative_axes` or (if the former is not provided), the number</span>
<span class="sd">        of spatial dimensions in `tensor_field` (``m``).</span>

<span class="sd">        Specifying `first_derivative_field` can be used to avoid having to compute the</span>
<span class="sd">        relevant derivatives numerically, which can improve efficiency and accuracy.</span>
<span class="sd">    second_derivative_field :  numpy.ndarray, optional</span>
<span class="sd">        Precomputed second derivatives of the `tensor_field` with shape ``tensor_field.shape + (q,q)``, where</span>
<span class="sd">        ``q`` is the number of axes in `derivative_axes` or (if the former is not provided), the number</span>
<span class="sd">        of spatial dimensions in `tensor_field` (``m``).</span>

<span class="sd">        Specifying `first_derivative_field` can be used to avoid having to compute the</span>
<span class="sd">        relevant derivatives numerically, which can improve efficiency and accuracy.</span>
<span class="sd">    edge_order : {1, 2}, optional</span>
<span class="sd">        Order of accuracy for boundary differences. Default is 2.</span>
<span class="sd">    out: numpy.ndarray, optional</span>
<span class="sd">        An output buffer into which the result should be written. This should be an ``(..., ndim, ...)`` array</span>
<span class="sd">        where the leading indices are the broadcasted shape of the spatial components of the `tensor_field`, `Fterm_field`,</span>
<span class="sd">        and the `inverse_metric_field`. The trailing indices must match the non-spatial shape of the `tensor_field`.</span>
<span class="sd">        If `out` is not specified, then a new buffer will be created with the correct shape.</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    ~numpy.ndarray</span>
<span class="sd">        Laplacian of `tensor_field` with shape ``tensor_field.shape``.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This function assumes a full inverse metric (not diagonal) and uses upper-triangular evaluation of</span>
<span class="sd">    second derivatives to reduce computation using symmetry.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    dense_gradient_covariant</span>
<span class="sd">    dense_scalar_laplacian_diag</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>

<span class="sd">    This example demonstrates computing the Laplace-Beltrami operator for a scalar field</span>
<span class="sd">    in 2D **spherical coordinates** :math:`(r, \theta)`.</span>

<span class="sd">    We define the scalar field:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \phi(r, \theta) = r^2 \cos(\theta)</span>

<span class="sd">    The Laplace-Beltrami operator in spherical coordinates is given by:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \Delta \phi =</span>
<span class="sd">            \frac{1}{r^2} \frac{\partial}{\partial r} \left( r^2 \frac{\partial \phi}{\partial r} \right)</span>
<span class="sd">            + \frac{1}{r^2 \sin\theta} \frac{\partial}{\partial \theta} \left( \sin\theta \frac{\partial \phi}{\partial \theta} \right)</span>

<span class="sd">    which expands to:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \Delta \phi =</span>
<span class="sd">            F^\mu \, \partial_\mu \phi + g^{\mu\nu} \, \partial_\mu \partial_\nu \phi</span>

<span class="sd">    where:</span>

<span class="sd">    - :math:`F^r = \frac{2}{r}`, the derivative of :math:`\log r^2`</span>
<span class="sd">    - :math:`F^\theta = \cot(\theta)`, the derivative of :math:`\log \sin(\theta)`</span>
<span class="sd">    - :math:`g^{rr} = 1`, :math:`g^{\theta\theta} = \frac{1}{r^2}` are the components of the inverse metric</span>

<span class="sd">    .. plot::</span>
<span class="sd">        :include-source: True</span>

<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import matplotlib.pyplot as plt</span>
<span class="sd">        &gt;&gt;&gt; from pymetric.differential_geometry.dense_ops import dense_scalar_laplacian_full</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # --- Grid in spherical coordinates --- #</span>
<span class="sd">        &gt;&gt;&gt; r = np.linspace(0.01, 1.0, 100)</span>
<span class="sd">        &gt;&gt;&gt; theta = np.linspace(0.1, np.pi - 0.1, 100)  # avoid tan(theta)=0</span>
<span class="sd">        &gt;&gt;&gt; R, THETA = np.meshgrid(r, theta, indexing=&#39;ij&#39;)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # --- Scalar field phi(r, theta) = r^2 * cos(theta) --- #</span>
<span class="sd">        &gt;&gt;&gt; phi = R**2 * np.cos(THETA)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # --- F-term: [2/r, cot(theta)] --- #</span>
<span class="sd">        &gt;&gt;&gt; Fterm = np.zeros(R.shape + (2,))</span>
<span class="sd">        &gt;&gt;&gt; Fterm[:,:,0] = 2 / R</span>
<span class="sd">        &gt;&gt;&gt; Fterm[:,:,1] = 1 / (R**2 * np.tan(THETA))</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # --- Inverse metric --- #</span>
<span class="sd">        &gt;&gt;&gt; IM = np.zeros(R.shape + (2,2))</span>
<span class="sd">        &gt;&gt;&gt; IM[..., 0,0] = 1</span>
<span class="sd">        &gt;&gt;&gt; IM[..., 1,1] = 1 / R**2</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # --- Compute Laplacian --- #</span>
<span class="sd">        &gt;&gt;&gt; lap = dense_scalar_laplacian_full(phi, Fterm, IM, 0,2,r,theta)</span>
<span class="sd">        &gt;&gt;&gt;</span>
<span class="sd">        &gt;&gt;&gt; # --- Plot --- #</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.imshow(lap.T, origin=&#39;lower&#39;, extent=[0.01, 1.0, 0.1, np.pi - 0.1], aspect=&#39;auto&#39;, cmap=&#39;viridis&#39;)</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.colorbar(label=r&quot;Laplacian $\Delta \phi$&quot;)</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.title(r&quot;Laplacian of $\phi(r, \theta) = r^2 \cos(\theta)$&quot;)</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.xlabel(&quot;r&quot;)</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.ylabel(r&quot;$\theta$&quot;)</span>
<span class="sd">        &gt;&gt;&gt; _ = plt.tight_layout()</span>
<span class="sd">        &gt;&gt;&gt; plt.show()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># --- Relevant Constants --- #</span>
    <span class="c1"># Extract the shapes from the arrays so that we</span>
    <span class="c1"># can work with them.</span>
    <span class="n">field_ndim</span><span class="p">,</span> <span class="n">fterm_ndim</span> <span class="o">=</span> <span class="n">tensor_field</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="n">Lterm_field</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">tf_shape</span><span class="p">,</span> <span class="n">imf_shape</span><span class="p">,</span> <span class="n">ftf_shape</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tensor_field</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">inverse_metric_field</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">Lterm_field</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">_buffer_shape_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_shapes</span><span class="p">(</span>
        <span class="n">tf_shape</span><span class="p">[:</span> <span class="n">field_ndim</span> <span class="o">-</span> <span class="n">rank</span><span class="p">],</span>  <span class="c1"># spatial component of TF</span>
        <span class="n">imf_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span>  <span class="c1"># spatial component of IMF</span>
        <span class="n">ftf_shape</span><span class="p">[:</span> <span class="n">fterm_ndim</span> <span class="o">-</span> <span class="p">(</span><span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)],</span>  <span class="c1"># spatial component of the Fterm field.</span>
    <span class="p">)</span>

    <span class="c1"># Propagate the varargs out in case they are</span>
    <span class="c1"># scalar.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">varargs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">varargs</span> <span class="o">*=</span> <span class="n">field_ndim</span>

    <span class="c1"># Fill in missing information.</span>
    <span class="k">if</span> <span class="n">field_axes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">field_axes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">field_ndim</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">derivative_axes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">derivative_axes</span> <span class="o">=</span> <span class="n">field_axes</span>

    <span class="n">derivative_axes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">derivative_axes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">field_axes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">field_axes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># --- Generate the output buffer --- #</span>
    <span class="c1"># the output buffer needs to be broadcast compatible</span>
    <span class="c1"># with the various fields.</span>
    <span class="k">if</span> <span class="n">out</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">_buffer_shape_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tensor_field</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>

    <span class="c1"># --- Compute Term 1 --- #</span>
    <span class="c1"># The first term is the contraction between the F-terms and the</span>
    <span class="c1"># first derivatives.</span>
    <span class="k">if</span> <span class="n">first_derivative_field</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># The first derivatives needs to be computed. We either want to</span>
        <span class="c1"># do this and allocate for it (if we need them later) or just</span>
        <span class="c1"># pass through and dump (if we don&#39;t need them later).</span>
        <span class="k">if</span> <span class="n">second_derivative_field</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># We will need to allocate the second derivatives so we</span>
            <span class="c1"># need to hold onto the 1st derivatives.</span>
            <span class="n">first_derivative_field</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
                <span class="n">tf_shape</span> <span class="o">+</span> <span class="p">(</span><span class="n">ndim</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span>
            <span class="p">)</span>
            <span class="n">dense_gradient_covariant</span><span class="p">(</span>
                <span class="n">tensor_field</span><span class="p">,</span>
                <span class="n">rank</span><span class="p">,</span>
                <span class="n">ndim</span><span class="p">,</span>
                <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
                <span class="n">field_axes</span><span class="o">=</span><span class="n">derivative_axes</span><span class="p">,</span>
                <span class="n">output_indices</span><span class="o">=</span><span class="n">field_axes</span><span class="p">[</span><span class="n">derivative_axes</span><span class="p">],</span>
                <span class="n">out</span><span class="o">=</span><span class="n">first_derivative_field</span><span class="p">,</span>
                <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># Dump the contraction result to `out`. We have all `ndim` elements in `Fterm`.</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
                    <span class="n">Lterm_field</span> <span class="o">*</span> <span class="n">first_derivative_field</span><span class="p">,</span> <span class="n">_buffer_shape_</span> <span class="o">+</span> <span class="p">(</span><span class="n">ndim</span><span class="p">,)</span>
                <span class="p">),</span>
                <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># We don&#39;t need to store the derivatives in memory because we only use them</span>
            <span class="c1"># once so we can just go through and compute the derivatives.</span>
            <span class="k">for</span> <span class="n">diff_index</span><span class="p">,</span> <span class="n">diff_axis</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">derivative_axes</span><span class="p">):</span>
                <span class="n">comp_index</span> <span class="o">=</span> <span class="n">field_axes</span><span class="p">[</span><span class="n">diff_index</span><span class="p">]</span>
                <span class="n">out</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
                    <span class="n">Lterm_field</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">comp_index</span><span class="p">]</span>
                    <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
                        <span class="n">tensor_field</span><span class="p">,</span>
                        <span class="n">varargs</span><span class="p">[</span><span class="n">diff_index</span><span class="p">],</span>
                        <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
                        <span class="n">axis</span><span class="o">=</span><span class="n">diff_axis</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">_buffer_shape_</span><span class="p">,</span>
                <span class="p">)</span>

    <span class="c1"># --- Compute Term 2 --- #</span>
    <span class="c1"># At this stage, we take advantage of Schwarz&#39; Theorem to cut down on the number</span>
    <span class="c1"># of derivatives we actually have to compute. We just use the upper triangular segment</span>
    <span class="c1"># of the second derivative tensor.</span>
    <span class="k">if</span> <span class="n">second_derivative_field</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># We are already given the second derivative field, so we just need to ensure</span>
        <span class="c1"># that the summation occurs properly.</span>
        <span class="n">out</span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">second_derivative_field</span> <span class="o">*</span> <span class="n">inverse_metric_field</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">)),</span>
            <span class="n">_buffer_shape_</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># We don&#39;t already have the derivatives so we need to perform the computation.</span>
        <span class="c1"># For this, we&#39;re going to cycle through all upper-triangular pairs of the derivative</span>
        <span class="c1"># axes.</span>
        <span class="n">number_of_derivative_axes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">derivative_axes</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">triu_indices</span><span class="p">(</span><span class="n">number_of_derivative_axes</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">a_index</span><span class="p">,</span> <span class="n">b_index</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">indices</span><span class="p">):</span>
            <span class="c1"># We first need to take the a/b indices and determine the field axes</span>
            <span class="c1"># and then the component axes.</span>
            <span class="n">a_field_index</span><span class="p">,</span> <span class="n">b_field_index</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">derivative_axes</span><span class="p">[</span><span class="n">a_index</span><span class="p">],</span>
                <span class="n">derivative_axes</span><span class="p">[</span><span class="n">b_index</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">a_comp_index</span><span class="p">,</span> <span class="n">b_comp_index</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">field_axes</span><span class="p">[</span><span class="n">a_field_index</span><span class="p">],</span>
                <span class="n">field_axes</span><span class="p">[</span><span class="n">b_field_index</span><span class="p">],</span>
            <span class="p">)</span>

            <span class="c1"># We now need to compute the second derivative. This will be the derivative of</span>
            <span class="c1"># the first_derivative_field[..., a_comp_index] with respect to the b_index vararg and</span>
            <span class="c1"># on the b_field_index axis.</span>
            <span class="n">factor</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">a_index</span> <span class="o">==</span> <span class="n">b_index</span> <span class="k">else</span> <span class="mi">2</span>
            <span class="n">out</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span>
                <span class="n">factor</span>
                <span class="o">*</span> <span class="n">inverse_metric_field</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">a_comp_index</span><span class="p">,</span> <span class="n">b_comp_index</span><span class="p">]</span>
                <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span>
                    <span class="n">first_derivative_field</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">a_comp_index</span><span class="p">],</span>
                    <span class="n">varargs</span><span class="p">[</span><span class="n">b_index</span><span class="p">],</span>
                    <span class="n">axis</span><span class="o">=</span><span class="n">b_field_index</span><span class="p">,</span>
                    <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">_buffer_shape_</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">return</span> <span class="n">out</span></div>



<div class="viewcode-block" id="dense_scalar_laplacian">
<a class="viewcode-back" href="../../_as_gen/differential_geometry.dense_ops.dense_scalar_laplacian.html#differential_geometry.dense_ops.dense_scalar_laplacian">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">dense_scalar_laplacian</span><span class="p">(</span>
    <span class="n">tensor_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">Lterm_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">inverse_metric_field</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">rank</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">ndim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
    <span class="n">field_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">derivative_axes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">out</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">first_derivative_field</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">second_derivative_field</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">edge_order</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the Laplacian (Laplace-Beltrami operator) of a tensor field in a general</span>
<span class="sd">    curvilinear coordinate system, using either a full or diagonal inverse metric.</span>

<span class="sd">    This function implements:</span>

<span class="sd">    .. math::</span>

<span class="sd">        \Delta T = F^\mu \, \partial_\mu T + g^{\mu\nu} \, \partial_\mu \partial_\nu T</span>

<span class="sd">    and dispatches to the appropriate low-level method depending on the shape of the inverse metric.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor_field : numpy.ndarray</span>
<span class="sd">        Input tensor field of shape ``(F1, ..., Fm, ...)``, where the final axes (if any) correspond</span>
<span class="sd">        to tensor indices, and the first ``m`` axes are spatial.</span>
<span class="sd">    Lterm_field : numpy.ndarray</span>
<span class="sd">        Log-volume term array of shape ``(..., ndim)``, where the last axis matches the number of coordinate directions.</span>
<span class="sd">    inverse_metric_field : numpy.ndarray</span>
<span class="sd">        Either a diagonal inverse metric (shape ``(..., ndim)``) or a full tensor (shape ``(..., ndim, ndim)``).</span>
<span class="sd">    rank : int</span>
<span class="sd">        Number of trailing axes of `tensor_field` corresponding to its tensor rank.</span>
<span class="sd">    ndim: int</span>
<span class="sd">        The number of total dimensions in the relevant coordinate system. This determines the maximum allowed value</span>
<span class="sd">        for ``m`` and the number of elements in the trailing dimension of the output.</span>
<span class="sd">    *varargs :</span>
<span class="sd">        Grid spacing along each axis. Must match number of spatial axes or derivative axes.</span>
<span class="sd">    field_axes : list of int, optional</span>
<span class="sd">        Maps each spatial axis of `tensor_field` to a corresponding coordinate axis.</span>
<span class="sd">        Defaults to `[0, 1, ..., m-1]`.</span>
<span class="sd">    derivative_axes : list of int, optional</span>
<span class="sd">        Subset of axes over which derivatives are taken. Defaults to `field_axes`.</span>
<span class="sd">    out : numpy.ndarray, optional</span>
<span class="sd">        Output buffer to store result. Must be broadcast-compatible with spatial shape of inputs.</span>
<span class="sd">    first_derivative_field : numpy.ndarray, optional</span>
<span class="sd">        Optional precomputed first derivative field of shape ``tensor_field.shape + (ndim,)``.</span>
<span class="sd">    second_derivative_field : numpy.ndarray, optional</span>
<span class="sd">        Optional precomputed second derivative field of shape ``tensor_field.shape + (ndim, ndim)``.</span>
<span class="sd">    edge_order : {1, 2}, default=2</span>
<span class="sd">        Accuracy order of numerical finite differences.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    numpy.ndarray</span>
<span class="sd">        Laplacian of the input tensor field, with shape ``tensor_field.shape``.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If the metric type is not recognized.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">spatial_shape</span> <span class="o">=</span> <span class="n">tensor_field</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span> <span class="n">tensor_field</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="n">rank</span><span class="p">]</span>
    <span class="n">metric_type</span> <span class="o">=</span> <span class="n">infer_metric_type</span><span class="p">(</span><span class="n">inverse_metric_field</span><span class="p">,</span> <span class="n">spatial_shape</span><span class="p">)</span>

    <span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">field_axes</span><span class="o">=</span><span class="n">field_axes</span><span class="p">,</span>
        <span class="n">derivative_axes</span><span class="o">=</span><span class="n">derivative_axes</span><span class="p">,</span>
        <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">,</span>
        <span class="n">first_derivative_field</span><span class="o">=</span><span class="n">first_derivative_field</span><span class="p">,</span>
        <span class="n">second_derivative_field</span><span class="o">=</span><span class="n">second_derivative_field</span><span class="p">,</span>
        <span class="n">edge_order</span><span class="o">=</span><span class="n">edge_order</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">metric_type</span> <span class="o">==</span> <span class="s2">&quot;full&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dense_scalar_laplacian_full</span><span class="p">(</span>
            <span class="n">tensor_field</span><span class="p">,</span>
            <span class="n">Lterm_field</span><span class="p">,</span>
            <span class="n">inverse_metric_field</span><span class="p">,</span>
            <span class="n">rank</span><span class="p">,</span>
            <span class="n">ndim</span><span class="p">,</span>
            <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">metric_type</span> <span class="o">==</span> <span class="s2">&quot;diagonal&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">dense_scalar_laplacian_diag</span><span class="p">(</span>
            <span class="n">tensor_field</span><span class="p">,</span>
            <span class="n">Lterm_field</span><span class="p">,</span>
            <span class="n">inverse_metric_field</span><span class="p">,</span>
            <span class="n">rank</span><span class="p">,</span>
            <span class="n">ndim</span><span class="p">,</span>
            <span class="o">*</span><span class="n">varargs</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unrecognized metric type: </span><span class="si">{</span><span class="n">metric_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span></div>

</pre></div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2024, Eliza Diggins.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>